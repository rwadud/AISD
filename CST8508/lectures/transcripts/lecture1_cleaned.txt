
The rise of deep learning techniques brought a drastic change in the field of machine vision. So it's the rise of deep learning technique that brought in drastic change in the field of machine vision.

Now, let's take a look at the key technology. As I mentioned, there are mainly three steps. First is image capturing. For capturing the image, we need some devices, right? So we can use cameras or sensors for this. The popular or most commonly used image sensors are CCD and CMOS, which are widely used in our cameras. Smartphone cameras and digital cameras all use CCD and CMOS.

The image sensor is one of the key technologies. The second step, once we have acquired the image using the sensors, is processing that image. For that, we need some techniques. So that is the second technology: image processing techniques. An example is feature and edge detection, which you are doing in your lab activity. You are using some filters, like Canny edge detection. All those things are technologies used in machine vision.

The final one is the role of machine learning. Particularly, deep learning is the key turning point. All these technologies work together to enable machines to understand visual data. So what are they? Sensors, processing techniques, and machine learning, especially deep learning. All these technologies make up machine vision.

So what are the applications of machine vision in everyday life? We see machine vision everywhere, every day. From your cell phone, using facial recognition to unlock your smartphone, you are dealing with machine vision technology daily.

It is actually used for barcodes. When you go to Walmart or any other supermarket, you can pay by yourself by scanning the barcode. When you scan the barcode, you get all the information. That is one application of machine vision.

It is also used for inventory management. For employees working as inventory storekeepers, they can keep track of inventory, like how many packets of milk are there. If the shelves are empty, it will alert them to restock. So all these are some of the applications in retail.

In the manufacturing industry, as I mentioned earlier, it can be used for quality checks on the assembly line. We have devices over conveyor belts that take images of the products and then process them to compare with expected values. If it matches, they can pass. If not, we can say the product is not good. So that's how we use machine vision in manufacturing.

Another field is entertainment. In movies, we see a lot of visual effects these days. That is a practical application in entertainment. We also have augmented reality for games. All these are simple examples in entertainment.

In the automobile industry, there is a big change. Now we have self-driving cars. This is not possible without machine vision because the sensors analyze the image, process it, and make rapid, instant decisions. If an obstacle is there, it doesn't hesitate; it just applies the brake at that moment. Machine vision systems are not simple because they need quick decision-making capacity, especially for life-threatening systems. Depending upon the criticality of the system, you need to choose which algorithm to use.

It is also helping in lane keeping, traffic sign detection, and adaptive cruise control. All those are practical scenarios or applications of machine vision in automobiles. You can think about how these technologies are helping our everyday life, making our lives much easier.

We can also take a look at one of the impacts. As we mentioned earlier, autonomous vehicles use it for navigation. In the healthcare industry, machine vision is used even for diagnosing diseases. From medical image scans, the system can detect whether there is a tumor, fracture, or other issue. It can suggest to doctors symptoms of certain diseases. It is used for diagnostics and robotic surgeries, which are very common these days. Those are very practical applications of machine vision in advanced fields.

Another one is facial recognition systems that enhance security. Even in airport security systems, machine vision can be used for security purposes. These applications highlight the transformative power of machine vision.

In agriculture, machine vision on drones can help farmers monitor their crops. It is also used to determine when crops are ready for harvest and to sort good produce from bad, such as separating good apples from damaged ones. The e-commerce industry also utilizes machine vision.

We have a case study on how machine vision was used during COVID-19. In COVID-19, we had access control to supermarkets and public spaces based on machine vision systems. There was a limit on the number of people inside the supermarket, so they had a count of people entering and leaving. There were also fever detection cameras, which are thermal cameras that can sense your temperature. If you have a temperature like 37 degrees Celsius, they can identify a fever. Another application is social distancing detection and face mask compliance. If you were not wearing a face mask, you could be detected by the camera.

The workflow of a machine vision system can be summarized in three steps: image acquisition, image processing, and interpretation or action.

First is image acquisition, which means acquiring the image by capturing it using sensors or cameras.

Second is image processing, where you do the analysis. We analyze and manipulate the image. Sometimes the captured image is not clear, so you can apply techniques to make it sharper and provide more detail for visualization. Image processing is very important for machine vision. This is where we prepare our data or polish our dataset to use as input.

Third is interpretation or action. This is where your actual model works. We make a decision based on the data we get from step two. For example, in an automated inspection system in manufacturing, we capture the image, do some processing, compare with expectations, and then make a decision.

Image processing forms the core of machine vision. Without processing, the machine vision system cannot perform. We have different formats for images, like RGB, and different color spaces. Color spaces define how color is represented. We deal with different types of images, which means different types of content for our dataset, so we need to normalize or prepare the dataset using image processing.

We can read the image, display the image, and change it into a different color space. We can do edge detection or filtering by smoothing or sharpening. I can show you an example using an image of a Husky. As you know, we are using OpenCV for our lab activities because it is a tool that helps with image manipulation. It is not used for developing or training your model but specifically for processing images. In our lab, we import `cv2`. Since we cannot use `cv2.imshow` in Google Colab because it doesn't have access to the system window, we use `cv2_imshow` from the package `google.colab.patches`. We read the image using `cv2.imread` and print the shape.

`image.shape` returns a tuple giving the height, width, and number of channels. For example, 555 for height, 830 for width, and 3 for the channels (Red, Green, Blue). If it was a grayscale image, we would just have the height and width because there are no channels.

`print(image)` prints all the pixel array values. For example, `[33, 37, 42]` shows the RGB values for the first pixel. This represents the intensity of red, green, and blue for that particular pixel.

An image comprises a large number of pixels, which is the basic unit of an image. In a colored image, a pixel has red, green, and blue intensities. In a black and white (grayscale) image, it has values from 0 (black) to 255 (white).

Now regarding advanced techniques like Neural Networks. Computer vision has come a long way due to advancements in AI, especially neural networks or deep learning techniques. This evolution has revolutionized machine vision. Because of AI, we get more accurate systems that can recognize complex patterns from images. Even if objects are occluded or overlapping, neural networks can identify distinct objects.

CNN (Convolutional Neural Network) is one of the backbones for this. A CNN can automatically do feature extraction from images. CNN stands for Convolutional Neural Network because it uses the mathematical operation called convolution. It is a class of neural networks specifically applied to analyze visual imagery. Unlike traditional neural networks that process text or other data, CNNs are specifically for images or video.

CNNs are trained with a large amount of data (images). For example, if we train with a dataset of cats and dogs, and input an image of a cat, it goes through different layers and finally gives the output "cat". The system extracts useful information while passing through each layer and makes a decision.

There are several career opportunities in this field. You can be a machine vision engineer, a data scientist, or an AI specialist. A machine vision engineer designs and implements machine vision systems. A data scientist analyzes datasets and converts data into meaningful information. An AI specialist innovates new algorithms or technologies. Industries are actively seeking those with expertise in machine vision technology because there are a large number of applications requiring sophisticated, reliable solutions.
