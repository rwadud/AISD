By which processing, they cannot achieve any of the distribution. So today, we will cover, like, what a major processing is, and what is the importance of image processing, and what are the different steps involved in image processing? And we will see different image processing techniques, like, you know, filtering, sharpening, and finally, uh, detection, easy carryings, you have already done for your loved one, but just like whatever steps involved in it. Um, Then we will also see which histograms, English, Rashordi, and morphological operations, and finally, image transformation taken. So this is our ag today. Yeah, so, as I mentioned, you made your processing is the core of, uh, machine machine machine. So what do you do? So, you have seen your lab ward, you have an input image, you change it in a different car space. You need to play scale. So you have, and basically like doing something to manage the image into a different form. So you are making it more useful for your applications. So you don't want it in the, for example, you want to do some information so that you get more information from that image, to do some operation. So that's what major processing is doing it in worse manipulation and by manipulating it, you are analyzing that event. So from now, like, if you're taxing it, if you do, like, you know, energy detection, you can see what are the clear shape of its ears and eyes, all those stuff, right? So these are also helpful for training our model to identify a cat. And if you are working, you just a cat. Okay. So that's the importance of image processing and it is also used for enhancing the quality of input image. So you capture an image and it has like, you know, some light variation. It's not that clear. Then it's very difficult for our system to process it, right? So we need to make it and like, you know, we need to make some reprocessing of that image to make it more clear so that the system can let, you know, better understand that picture. So it can also be used to form enhancing the quality of the image. And by doing so, we can extract. meaningful information for it. So that's what special, like, previous processing is doing it, fishing issue. So why do we need it? Different reasons. I'm just highlighting some of them. The 1st one is, as I mentioned, enhancement. So when you have a large data set of images, because machine machine deals with images or video, right? So we are dealing with, like, visual data. not documents or tailors or details. So we have mostly dealing with social data. So we have a lot, like, our data set comprises of a large number of images or maybe videos. So sometimes the each image in the data, it may not be good enough to do the processing or training or model. So what we need to do is we need to enhance the look for the quality of that including age. For that, we can use our image processing. So by, we can enhance the quality by reducing the noise, like you did for the blurring, by doing the blurring, a little bit of the, you know, the noise is reduced. So that's one example, and you can enhance the contrast. So if you do a sharpening. It give more details. Like, it highlights the edges and, you know, those kind of features from the images. Yeah, so by doing so, it is easier for the system to analyze what is in that image. So that's the 1st poet enhancement. Second one is feature extraction. So it can be used for identifying and extracting important features like edges. So you have seen in edge detection, you are extracting the edges from the image, right? So this can be used for identifying adjust corners or blobs from the image. And what we need these edges and corners is that we need it for, like, you know, training the model to analyze the shape of the object or to recognize an object or do some classification based on what is the object incandating that image. So feature extraction is another reason why we need machine mission, sorry, image processing it, machine mission. Next 20 segmentation, this is one of the toughest tasks. Second edition is, as its name indicate, we divide or segment the image into small ingredients. So at each range, we have some useful information for us. So we need to settlement it carry. Okay, so this is another reason why we use image processing, image processing is used for segmenting, the image into meaningful radiant, and by, and this is very important technique, needed in object, detection and object classification, et cetera. Then object recognition. So, um, It's clear from the name in South India recognize object. So the machine machine technique or the image processing techniques can be used for recognizing object from the images. And so this is used in automated inspection, robotic, et cetera. And finally, the last one is the measurement. As I mentioned last week, one of the variation of vegetation is, in acidly legs, it can be used for plantation. So if we have any product, which is not meeting the quality, can like identify it by, you know, for example, the PCB board, if the components are not having the enough distance, as in the side, it can detect it. So for this, we need to measure the distance between the components or the size of the board, stuff like that, right? So the measure machine precides. So machine machine can help us for achieving that. So that's the 5th point. It allows for precise measurement of object dimension, distances and other parameters. So this is very widely in quality control and industrial automation. So these are the reasons why we need image processing in, preservation. Now, let's see what are the key stages in image processing. The first one is acquisition, so we need to acquire the image or capture the image. Second one is enhancement, so you can use, like, enhance the image, and restoration. So if anything gives me some feed, like, you know, gaps or something, they get you can even restore that, yeah, by performing some of the image processing technique, and the morphological processing, this is a processing technique, which is based on shapes, presenting that image. And again, segmentation into the device, image into different segments, and object recognition, it can recognize and identify what is plus a different image if it is a cat, or a dog, or a car, or something like that. Then representation and description is a way of representation, like where you're representing the data. So, if you have, like, captured enough information, but what we captured is not enough for the computer to understand it. So we need to represent it in a way, that computer can understand, right? So that's what representation and description means. And finally, image compression is needed when we have a large size of data, but we have a storage image or like, you know, space imitation, then we can come from the image. So that's the image compression and last one is colour image processing. It's everybody makes processing based on colours. So these are the different stages in image processing. You can go through it in detail. I have added an asynchronous material for week 2. So it has like what, one of the different stages. So keep in mind that we don't need all the 9 stages for our application, depending upon your application, you can like make a combination of like 2 or 3 of them. So that's this mission. So based on the application, a combination of 2 or 3 steps can be used. It's not mandatory that you have to for all the United States, which I mentioned in the earliest life. So we can go through each stage in detail. So the 1st one is image acquisition. So what we are doing, we are acquiring image using cameras or sensors. So most commonly ones are CCD and CMO sensors, which are used in digital cameras. And next to one is image enhancement. So this is where we manipulate our equal image. But we are like, you know, polishing our image, so that it can be used for our processing. The image is not good enough to do our processing. We need to do enhancement by, you know, like by doing some sharpening, bringing out the leader need days, or who are blurring to hide out the noise from it. So depending upon the quality of your input image, you can perform the image enhancement. Next one is image restoration. So it is, again, the process of improving the appearance of image. So, here, example, is remote of noise, it can remove the noise and restore the content and also sometimes some missing gaps will be there for, you know, there are some bridge connections between 2 objects. Sometimes it's missing, you can restore it by doing some image processing techniques, which it is. Is there morphological processing? This is, again, like, you know, it's more connected to shapes. And an exam for the application is the fingerprint recognition. So these are the key stages. most. Yeah, the next one is the main segmentation. As I mentioned earlier, this is one of the most difficult tasks, but this is the core, like, you know, technique for performing the classification. So this is very important, image segmentation. So as its name indicated, they buy the input image in different segments from, you know, different regions. Object recognition. As I mentioned, it can recognize one as present in the image, and it can label it. So it is label to adopt it based on the information provided by the description. And representation of description, as I mentioned, it is converting the data into a form that is more understandable for the habitat. So what is human, can understand, cannot be understood by the machine, right? So that being to represent it in a binary form or like the form which the computer can understand. So that's the step of representation and description means. Then image compression, as I mentioned, you all know, like image compression, reducing the storage, preferred to stall that image. And current into processing inwards, the use of power of image to extract meaningful information. So these are the different stages. and we have the machine asynchronous, um, material section in your rice based. So you can go through it, like, you know, iniquities the same, like, details for each stages. Yeah, now at stake, um, take a look at different, uh, take place. The one has, like, you know, um, the filters, uh, filtering is one of the age processing, and it is very, uh, useful technique, which is widely used in the vaccination system. So in the small video, you can see a filtering operation. We have an input image and a kernel and an output image. So I'm not going to explain you how the operation is working, that maybe like a week forecast. This is basically a federation of question. So we will see, in detail, how to perform their communication oppression in the upcoming classes, but this is giving you a high-level idea of like what's happening with filtering. So when you apply a filter, what happens is we have an input image, let's say, um, input image, and the other is the whole fix, and we are conforming it with a carnel, K, and carnel and painter are the same. Don't get confused with the word, or they are the same. 3rd size or futive size. It's the same. Okay. We are converting it with a kernel and we need output, G of X. So did you notice that the input size, dimension, like input image has a size of 6, 5, 6, 3, by 3, by 3, and on that for by 4, which means we take what is needed for our, you know, our processing or our system. We don't want all the pistols in the image. We just need what is important for us. So this congregation operation can help us to pick only the important information and it also help us to reduce the size at the cox. Okay, so from 6 dimensional to 4 dimensional. So it reduces the size and also it gives us important interaction. So it's a very useful operation, the convolution operation. So we will learn about like how to perform this organization upcoming us. Yeah. So, see, as this in the video, you can see, we have the input image and we have the kernel and we are passing the like, you know, we are passing the kernel from laptop left to the right, along the wood, and then we go along the height again. It is towersing through, across all the animals. Okay, I mean all the pieces in the image. So if you touch all the pictures in the image, and if you pick what is needed, and put it in the output image. So, it's a image processing picnic, which is used in a hand plate or enhance an image by all bring its fixers. So that's what exactly goes from each fixer in the image, and then it performs some computation operation, and alter that itself into a different form, which is useful for us. And by doing so, we can amplify certain features like, you know, some borders or anything, depending upon the 3rd L that we chose. And you can also suppress advantage sloshes or noise from the image as well. So this is useful for both, for highlighting the features and for suppressingly. Okay, so it just acts like a C through which, and so it adds like a C through which, original image of C has. So when the image is passing through the sea, what happens is like it can highlight specific attributes and it can remove all the noise from it. By doing so, we get an output image, which is good enough for us to do further analysis. Okay, so our input was not so good to do the analysis, we did some, you know, make some polishing using the filtering technique and when we then we get a final output image, which is useful for us to do the analysis. So basically we are doing some, you know, cleanup on our, to make it more useful. So that's theuring any. Okay, so next one is to reach flurry. It's also like if you drink operationally, but depending upon the current we use, it becomes blurring or shabby. So it's, the basic idea is, again, the convolution operation. So, here, also, you can see an input image and an output image. So the below, you can see how a blurred image would look like, it's not so clear, right? It's just blurry. In other words, we can say we feel like it's a smoother image. Okay, so blurring is a type of flurring that is helping us to smoother an image. So by doing so, it can, you know, it can reduce both detail and over some cases, this can be used as the faster stage to produce the noise. then if you apply another filter, it can, you know, maybe sharpening, it can highlight the important features. So you may have it or why we need to like reduce the details. So there are like some scenarios where we don't want much detail, but we need to get rid of noise. So this can be used as a faster stage in most of the, I think. For example, in carriage, detection. We do a blurring to remove the notes, right? And even the details are also hidden, but we don't want all the details. We just want the edges from it. But that, like, we perform, they carry edge on top of that, blurring edge. So I'm just saying that this is used to for suppressing noise. So that's the main idea. For removing the noise, we was blurry. How it works is it works by averaging the pixel around a target, for example, if we have... Um, what do you mean? So, this is, let's say this is our English, which is, like, black. We want to, like, smooth in this image, what we do is, we set up the Italian pizza. So this is how Thailand picks up now, the middle one. What we do is we take average of all the pieces, and then just stay wide. So if we choose a 3 by the size, So plus we consider this 3 by 3. And we take average of all the pixel values here and replace it. Okay, so however the information would look like this, um, So this is the pizza here, right? This one. But in our output image, like, we don't have this, uh, the more decision, but I'm just showing you, right? So we will take this target picture, I bring basically the average of all the pizzas under this garden. Okay, so if you add all the 0s in this room, right? So if you need a replace by, zero. So what you mean that this time is the representation of all the pizza around? So it's just representing all those style or how many of the same pixels around? So when you move this, uh, kernel, to the next high question, it comes here, right? So Here. So now we are transferring the next set off, makes sense. Okay, so now we move our carnel, one mixer to the right. Okay, now we are transferring, this video one. Okay, which is here, this one. And what we do is, we take average of all the pixels around it and replace it with that average value. So, if you do a calculation, like, we have a tiny, and divide it by nine, all the pieces, number of pieces times. So, you should have 10 here, right? So this will be 10. And when we move it, one piece of to the right again, you know, you mean like this, and we have 90%, 18, but in my time, it's just... So you can see um, You can see, like, from 0 to 9, you said, plastic change, right? From plan to kind of... 39, you grow them? This one? No, the minus zero. zero. Oh, why? Anything else is zero. On the right side, there is an answer. Oh, this is so... Sorry, sorry, sorry. Should they say it? Okay, thanks for that. Yeah, okay. Yeah. That's correct, yeah. I'm glad that you got the recording. Yeah, so the idea is that So we have you know that when C what tonight is a plastic change, right? What being here is like, you know, it was some part also tend to believe me, it's like the smoother transition. So the Indian city is distributed almost normally, not a drastic change, right? So this is how we make our image blurry. So even the darker coin will look like a greyish. So that's the main idea behind the rain. So, yeah, so this is used for softening the image, and the basic idea is to reduce the noise. Okay, any any doubt on this? Good. Okay, next one is image sharpening. It is exactly the opposite of what you did now. This is used actually for enhancing the need, not for suppressing or removing, but instead, we will enhance the details, presenting that, imaging. Again, we have it's all the same operation, the federation operation, or... similar to the future. But depending upon the kernel, the art would change. So here, if you look at that current. So what they show here in the Metrics is a card. So maybe, you can see that the isocen kernels have drastic virus, 02 minus one, minus one to 0, and when you go, next layer is minus one to 5, 5 to one. So it's not a, you know, like, you know, like, transitioning, it shows contrast to values, if that doesn't fix us, right? So if you apply such a curd and all form of an image, what you get is, you get, um, The, the, it embraces the corn grass intimately at the same pixels. So it can help you to highlight the edges or make it more, looking more finely. So that's the main idea of sharpening. So it's just all opposite to the blurring. Blurring makes it, you know, it's called like everything looks normalized or, you know, less contrast between the values. So even though it was contrast between zero and 90, we made it like 10, 20s, so matching, we normalized it. But here is the opposite. Even if it is 0, 10, 20, we make it like maybe 100 to minus 100 or, sorry, like -one, yeah, minus 100 or stuff like that. So, It's, it's trying to, uh, increase the hard grass basically, neighbourhood pizzas. Okay. So while we need sharpening, it can help us to attach the edges and details. This image is not that clear, but still, if you look from the sky, you know, if it is, this is the canvas, we have the roof. So this... So we have like, you know, a clear edge of that road, right? So this can be highlighted more clearly if you do that, sharpening. Even the corners and all the, you know, the design on top of it can be clearly, say if you do that, so it enthances that, details present in the image. So this is highly useful in medical imaging or precision manufacturing because you cannot compromise to the part of the image, we need more information in that case. Right. So, uh, this is highly useful in medically raising of precision manufacturing, where we, uh, where the details are very critical. Yeah, so we have seen how it was. So as I mentioned, it embraces the contrast between access and pixels to highlight the boundaries of objects within the image. So it keeps more contrast between the adjacent pieces. Then you can easily identify corners and energy, etc. That's what image sharpening is doing. Next one. Yeah, we can take a look at the different animations. Basically, this is the absolutely allowable question. I'm not sure if it is clear, but I will upload this, uh, next week. Yeah, week after, after it is up in your lap, too, because if there's any chance to be allowed to, as well. So you already know, like, how to rate the image and display, right? So there is like, this is how we do the sharply. Yeah, so this is how we do the shopping. So I have already showed you the ventries that we used to write, like 0 minus one zero, so that's just a different show contrast values. So this is the pixel that we defines the NPI array, and then we use the filter to be from, like, to function from open CB to apply, that is Japanese. And blurring, you already see how to put the buried for the carrier to it, that she already did the go simpler, so, you know, the go simpler, and then this is how they... Isn't it a website? Isn't the website? Is this? On the website? Uh, you mean in the right space? Not uploadedloaded labour because this have to your laptop for. Yeah. Yeah, so in this image, the 1st one is the original. 2nd one is the shop and new one, it will be more clear if you're opening your laptop, but later I'll share it. And the 3rd one is the blurred age. It's not that distinguishable from this. But in the 2nd image, you can see towards the like top of the head or towards the ear portion. clear in the 2nd image, right? Can you feel that? Yeah, if you closely look in up in your laptop, later, and you, you have to sell that. And resizing, this is scaling, because we have a state partner here. So if you ask me, what is the difference between staying and precising both are the same, and we use the same function, race size, but the difference is that in race size, you specifically say this exercise, I need the 300 by 300 pixel bids on high, right? You say, if you specify the retired height of the output image. But in scaling, what you do is you just need a ratio, because I can say I needed like half of the weight and double of the height. So it's likend factor. So that's what's gay. and recising is you exactly specify the with that time. Okay. So, um, this is, uh, scary, because we give the skate factors, it's a wide, and this is how, uh, the rotation you already did for your time. Um, some of you, because I heard, like, uh, some of you, like, I was studying the spicy operation, that's what I heard from, uh, yeah. This is how we get the height and bit of thinking. Last week. I showed you like what image, don't shape, will return, what page will return, right? If you if you look at that last 2 weeks, the IPI will be five, you will get an idea of it. So, how we get the high time with this, next image, don't shape, will rip them, basically, if it was an RGB or coloured image. So people will return green at the top of 3 varies, which is high. Wait at the number of channels. Okay. So, if it is a, let's say, 200, my...
see the image and the output is just a outline around the object, right? And it can clearly detect the shape of the image by floating the edges. So that's why we need engine detection to identify the object process that image. So can is one of the older and you know, very powerful engine detection mechan, it has like a lot of mathematical equational mathematical operation going under the world. But we taught how to worry about it because the opp is doing all the operations and we just want to call that canning function and pass our image and the other parameters. As for the function definition. So the canning filtraces and identity detection algorithm, and this is not for its precision in detecting edge, range of edges. So in this inputty image, it's stuff, you can clearly see it can it detected all the importance. So important edges, especially the edge that can identify the shape of e person, the camera, even the building in the bag, not everything is detected. They't miss out any important details present in the image. So how this is achieved, it involves different stages. The first one is the noise reduction, as I mentioned, the first step for almost all the image process, some cleaning up, right? Theput deb won't be putting up four hour process. So we need to make it good. Firstly you need a first part we do is we do some cleaner by removing the noise. Okay, for this, what we do for reducing the noise I mentioned, what we do blur right, right? Blurry can't help us to reduce the noise plus a little image. So we use CCN, it's a combination like in candy, they use closely. They recommend to use the to get the better result. because it uses, the mathem is the If you look at the open CV, if you search for Carrie, it will show you the questions of the mathematals, you know, Operations that is performed by everything. So noise redactionction is the past step, and second one is the gradient calculation. So for each mix up process image, it will calculate grad image, like, you know, the pixel intensity value and the daction along which the intensity is distributed. So it can have a magnitude and in direction. So you don't have to worry a lot about the mathematics behind it, but still, like, just to for your information. So this is the second step gradient, calculation. So it finds the indexity gradient and its direction and each qu itself. Okay, so it's always. So the gradient, how it boxes, like if you have an egg like this, it's always perpendicular to the edge. So if this is the edge, the ingredient action should maybe perpendicular to. an always said to how pixels are it, right? And the direction of all the pixels will be towards the right side. It's perpendicular to the direction of the edge. So that's the second step, and this smooth it? He may just filter with another car, which is a smallbil carnel, which is for removing the extra noises and the more clarity to theation. And this is what happens if you apply a solil tunnelist that itute the first generative in both horizontal and vertical direction. and this will help us to commute the magnitude and variant doctor, grad of each pizza, each. And the next step is the non-m suppression. So this is an important step, this is where we out our and just by suppressing the non gradient value. So we get a lot of values, but we don't need everything. We just need what is edge right. So how it works is, it perform a local maximumima suppression. So it compare with the labour perix this is the maximum, pixel value if it is the visible, maximum, then we will retain that burn to this minimum, we replace it with different one, like more, we just ignore it. So double thresholding is another step, so that's why I asked for a video of the students during the lab presentation. So we have two thresholds for Kenny, which is T1, let's say this is Devon and T2. So he should be something in the images taken and we becomeare in. And if that fixer value is less empty, what we just ignore it, we don't want to prote it into our footage, we just ignore it. And if it is like greater that it do we call it like stronger, like strong t. So greater will come strong edge. Anything below is what we ignore it. Anything between this range, any p value between this range isous, weak edge, but we don't ignore it in f. What we do is we do an it tracking by histois. So this is an algorithm that tracks it just by connecting b and just to the strong edges. So it check this algorithm and check if these are connected or if any of the be ed is connected to any of the strong edge. If there is any connection, then we will take that be edge. Otherwise, we just ignore it. So that is basically if you look at that image, A is a poet on the edge and C and B are different poems, which are also along the direction of the grade. So what we do is like, we check the if A is the local maximum. We'll check compare with the value of C and B, because they are the neighbourhood ones, which are also along the direction of the gradient. So being compare the intensity of A with B and C. And if it is the local maximum, we say good A is strong, we keep it. And next to Monday is, like we look for B and C. Both are along the lady direction. We check if it is coming under like, you know, strong point or beak point or, you know, it's below the threshold or. So if we draw a graph like this, this is the mean, this is the match. G2 A is, of course, here, and we can say C and something like this. So B, let's say, like B is out, and it is below the threshold. Let's say it is below the threshold. And then we won't have if it doesn't have any connection between A, we just not be. But C is also, but it has a connection with E, which to select both A and C. We just ignore B, because B is not connected even though it is Sp, it is not connected to AA is a stronger. So that's how the electrring my hist work. So these are the main steps. So just keep in mind, like what are the steps in holding can and injection, but you not have to worry about how to calcul the in extra direction by direction, how to calculate the like gradient angular or anything. So just like make sure that you understand how this double threshoding works and why we need two threshold in your lab, you pass like 100 and 200 as a thresh, but you don't know what it's doing, right? So that's what these are is showing. Your thresholds are, used to form, selecting the strong edge and the weaker just connected to the strong edge. And just ignore anything. It's just below that fresh one. I have slide, which is pointing to the TV, where you can where you can go through all the things like the gi explain how many you can pour res can to the under orse. So I just I thought it right if we have many questions here. This is how energy is thatated, this is how we direction, the angle is calculated.. that's it about the c detection. Do they sing and break before me before we down or what do you prefer? Play for five minutes? Yeah. And I can see a lot of sleepy faces. So, then again take five minutes break and come back at. Okay. I don' should end up in. to be fair. Threeers and it's like last semester. Also. Exactly. Oh sure, Friday's better. I think I go The thing is is like, now spending the day and off. Tuesday I should be sure. But like, warm. Do You have like a long week Yeah, exactly. You.. He doesn't explain the image. I am sure doesn't club.. She all the different functions. It's CB2 choice. C2 is this not. She a different function. important CD in this.. She still didn't upload the notes. She said she... What's.
that shows how many people in the has a particular like mile half in red colour and 200 pix in my age have like blue colour. So it's just like graph that shows how many pixels in the image have a particular brightness level. So the exactis would show you know, the different brightness levels and the yaxis would show the number of the p which belong to each brightness level. So the h the axis shows different brightness level from dark to light. So the left h value, the darkest to one, and the rihose be the brightest one. So let's say, yeah, you can see from zero to 250, right? So zero means black. And black is, 255 is.. white. It's say that. So from left, it's back, and when you move further towards the right, it becomes more right. So it helps us understand if funny be is mostly bright darker balance, that it's useful for improving the image is low. So if you have a daft like this and you have more ball here then you know, when you go here, so what is we did say back and fly to? It'serge, because it's the, like, you know, left right. So on the other, if it is showing more various in the right, you can see that it's a right relationship. So we 12 more barots. So that's the idea of kro.. So if it gives an over idea of the indexity distribution of an image, so how many pixes in the image have a particular indexity level? So it gives an overad idea about the intensity distribution and it has like violence ready from 0 to 255 in X axis and corresponding number of pixels in the Y axis. So the left region shows the amount of diar pixel and again is a repetition, but I'm just like making sure you get the point between the darker and brighter or. So towards the right rate is the riter. So we can also do one thing. You say right from 0 to 2 255. We have, you know, 256 values. So when we prod this, this will be like a huge dap, right? You know, 256 points speeding to plot. But if you make it into smaller beings or, smaller badients or small segments, we can make it smaller and more, you know, easier two process. So that's why we have the types of all bins. Okay, so since we have ranges from 0 to 55, we can make it 16th bins each have like, you know, 16 intensity bar. So it have like the first beam will be like 0 to 15 and the two will be 16 to 31 something like that and finally be four, sorry B 16 will be of what2, 255. So, like this, you will have 60 bins. Okay, 16 pins. So if you're fixing is having, let's say,ensity value 18, it will fall into bin two. If it has just like six, it will fall into bin one. So depending upon the intensity value, the the graph will be broader like that. So if you' take a unit of all these BB2 B3 up to B 16, you'll get the full C to 255 rangech. 10. So that's the concept of veins. You can read more about death in the h series. I have given in link there. That's all of the program has been and for allowed to unique to calculate the program of the image, but you cannot use the CD tool. I am sure to plot it. It's you can use the Mac plot link for pling. Okay. name. So this is one of the main techniques that would help us to perform the segmentation. So do you remember I mentioned segmentation is the most difficult task and in order to achieve this and that segmentation is very much needed for object classification and objective detection. So we cannot evolid segmentation. So how we actually segmentation base different techniques are there, one of the technique is So you get segment the image based on this on a shorting. So in this input image, you can see different, like, shades of grey, right, from white to black to different grey shades. But in the output thresholded image, what do you see is just black and white? Okay, so you like distinguish between foreground and the background. Okay. our focus was on that person. So in order to extract that person's image, what we did is we applied a thresholding and world. So if you look at the histogram in the middle, we applied a threshold on 100.. So we take every pixel in the input image of this original image and we check if that is below or if it is above 100. If it is below 100, what we do is, let's say we have via and pixel, how are exit. So we take the pixel and if we don't Thore, which is is 100. So since this is less than the threshold value, why we do the outside X2 like this, we make it crack. Okay. And when we change why, sponted in so far later, that the threshold might we do is we assign it to 255. Okay, so this is how we did the thresholding and has a result, what we get is we get black and white teenage, which clearly gives us distribution distinction between the foreground and the flyground. Okay, so thresholding is a symbol, but it's an effective way to perform semination. And by converting an image to black and white based on a threshold value, we can isolate objects or features easily. So from this input image, you can see right that person's images captured easily, right, by just applying the thresholding technique. So this is the use of thresholding. And the th can be done in different ways, as one is simple cash. Another one is adaptive. So the simple coding means for every pixel in the image, we have a single threshold, which is this exab, a scenario, like we have the threshold value 100. So every pixel in the image, we compare to this value of 100. Okay, so that is what simple thresholding is doing for every pixel, the same threshold value is apply. If the pixel value is smaller than the threshold, we set it to zero. If it is greater than we set it to the maximum value, which is the 255. So that is simple shortly. And adapting rusholding is different. The kind is always the same because in compared a particular value with the epixel and make decision. But the where we select thresholding is different. So in this case, like if we have an image like this and we divide the image four, this region have, let's say, the threshold is here, it will be wanted. Maybe this maybe 200, maybe this is 50. So algorithm can compute, which region will have, which threshold. So it's not like a single threshold, depending upon the pixel intensities. The algorithm will compute a threshold value. And it compares all the pixel element in that region with that particular threshold and make the decision. So that's what adaptive thresholding is doing. Sogorithm determines the threshold for a pixel based on a small regent around it. So we can different threshold for different regions of the same image, for the same image, we have different threshold for different regions. Okay, Got it? Yeah. So why do we need such a mechanic space, like, maybe you have some of you already did the lapl sement, so you choose some images with low lighting, right? So some lighting variations, somewhere where it's so more bright, somewhere it's very bright and like variation of bright and dark. So in that case, if you apply simple thresholding, you just become like, you know, a black and whiteer, you won't be able to distinguish properly. In that case, we may adaptive shortly. So this is very useful with the wages. This is having very illumination or like landing. Okay, soation of adaptive shortly. shortly is also similar to that, but instead of computing it different leagues. Instead of computing it, you know, like for a region, we have a particular threshold in a abue, right? So instead of that, we have a equation, which is based on the p equ. So that's why we have another, like, you know, type of ranting word was in the mathematical question is different, which is used in the algorithm. But that is also more useful in the scenarios with the poor likely. so the next one is morological operation. This is very important and morphology is a broad set of major processing and this is a technique, which is mostly dealing with shapes. So when mological operation, like any question regard is this, regarding of the shape, you can answer with the mological operation. So this is mostly dealing with shapes. And this is an example that I mentioned, because when I showed previously with my like, you know, the I refile, it was showing the images incorrectly. It was not able to like explain it properly, but with this image, it's a clear, right? So, first type of morological operation is erosion, we have four erosion, dilation, closing eropations. These are the major four morological operations. So first one is erosion, as its say, indicates it's, it shrinkes. Okay, so from these image itself, you can see, the input image, the letter is more wider, but in the outwood, it's trying, right? So this is where this is how the erosion was. So how it works is that it makes more, like no darker. So around the edges, for example, we have an image.. Okay, so let's like this is our input page, and we have a colonel, which is. So when we you know, through the se image, what it does this? it takes this first three b, right? And it check. There's all the input fix are a zero. Okay. Sorry, if it is a value, one, if not, like, if it is harm at least something. At least we' not. Okay, yeah, so all the pals under this one is one, then only it will be. Otherwise, what it does this it in one way zero. If everything is, we didn't take that one. Otherwise, what it does is it replace all the pictures are zero. So even if it has said like one in all these positions, you will mark us zero. So what basically justice? It makes the image more darker. So ities more black colour in bluey image, especially if it happensrounding edges. That's where you see the difference, right? Like, you being of zero and one will come around the edges. So it will change that once into zero so that the image we get darker. And the change shrinks. And as the go to the next location, you can see you can't it can also become. So if it will be rep all the p under this, all the pixels under this car is one, then only will be one. Otherwise, it will. So that's what theosh is doing. Yeah, if Pixel is originally made either one or will be considered one, only if all the pixels under the panel is one otherwise, it is on and all made it, two, zero. All the pixels near boundary we be discard depending upon the size of the colour, so that's what I mentioned. T the end, just only we have like zero sun parts, right? Otherwise you have either only one or zero in this advation. So towards that boundary, the thickus of the object decraces. And I like the thickness of the ground embraces and the background. background increases and the foreground increases. Yeah, so why where this is useful this, it is used for removing small white noises and being can be used to for detaching to connected objects, etc. So if it is this image like if two objects are connected, like this, this bridge will be important. If it is not at all. Like that kind of scenario would we can use because it breaks. So, when it's reducing the size, I know the attribute you'll have some zeros and one, so you can make everything zero, so that cy goes smaller. Then it moves to the next cell, right? The next cell, now, it is supposed to be in before reducing. It's supposed to be one, but now after reducing, it still have some zeros. Yeah. So, it's, you know. So it's not going to calculate before finishing whole calculation. Correct. So we are writing. We are not altering that. We have been writing into the new, right? So we are still dealing with the inputting. But what we get us an output is incredible. will stay like that, but out.. Yeah. So exactly opposite operation is the dilation of snake, indicates dilating exp. So you can see the object what expanded towards the catch. Because what it does is a fixed element is one, if at least to one pixel is one. So before it was one here, right? Yeah, so when the current passes, see where there is one one. So why does this the zeroins? So it keeps right to the image, like around the border. So that's how the dilation works. So it increases the vibrant in the image of size of allground object increases the other example, you see that the foreground decrease on the background increase here the o. Normally these cases like noise removal is erosion is by dension see later, and this is also useful in joining broken bags. So before we saw, if there is like any bridge which is no leader, we cannot omit thatage in this if it is needed, it will hide it. Okay. Yeah, so that's what dion is doing. Now we have to workation, what is opening and the other one is closing. is actually erosion followed by dig. So make sure you remember this because it is important for electra. So don't get confused with what is like, you know, opening and closing. So it's easy to, you know, a stage like I did, I also like, you know, what I just a little bit and I expl. So, opening and closing, now one is, you know, the first one is like opening is erosion forward by dimension. This is used for removing small of this. So in this image, you can see, there are like some white noises in the background, right? That isoted. in outboard. How it does this like first be two. Yeah, so must be shrin it will we shrink it all the, you know, like that white can just be become black, right? And then weate it. So when we dilate it, we get the original image. I mean, the output image will have the edges expanded. Okay, now, if you say like, you, there will be like three. So this is the including the first we do, you know, like Eurosh and then we get an output right on top of that output we are applying the dion. This is our company the? It's a combination all these techniques.. So that's what I'm saying like the future that we apply in our, forms, right? This is just a combination of people I take this that we use, like, you know, some increaseasingly sharpness, you know, in tright more, they just blur out the Bangalore and just focus. So all these are like, you know, the application of this prompt. Yeah, so this is how opening works and this is used for for joining the Bron and pants of an object, and, this is also for reducing the noise. So when we dial it, when we erolve, all the white noises will get blacked and it's remote, and then when we dial it and we get CO image more like, you know, the foreground is the equ. See the crossing is just opposite. be dilate, and then we strikes it or erode it. So it is useful in crossing smallb. So you can see like some missing informational gaps in this led, right? So when we dilated, it gets sprilled with white. Okay, then you shrink it. So it's like, you know, you get the original image that this out that lack yes. So this is used to have all these morphology progressions is highly used in, you, medically raging, where details is very physical and also ination application and document processing, example. You can see how we can clearly identify each letters. So it's very modern in document processing. So that's where are. Next one's image transformation dictate. Image transformmission dates are another like different typ of tools that can be used for various fortification andacts. So you have already beened above the headation translation, all theseamples of the transportation. And a fine transformation, it's in general term for classations like, you know, patients, sheers, transition, etc., we have any image, which has, you know, some parallel lines or stuff like that, but even after applying, transformation, we maintained that parabelism in that village, we don't make it well dot. We cannot do that with class permission. It will maintain all the parallelism and spl as it is, take outation. So the question behind this is why is it going to be where X is theination and the w is the output and A is the aff met, you know, like the rotation you already seen, like we created the rotation metrics.. And we that in the part of.. And B is that translation. It can shift the image to the left or right or top on bottom. So this is just an example of like how you can play around the image. And these are the examples: translation, ration scaly sharing, translation is nothing but shifter image in the exhort y direction. So the object can be replaced the close the left or right to a proper. So again, you can translate it. and rotation is rotating the image around this specified point. So for this, you remember, you will passascal within the heelment, then you find the centre of the image for redating, right? So that's what mentioned. So rotating the image around this specifying, you would specify that point as the cent of the image and based on the central rotation. The scaling, as I mentioned, it changes the size by a scaling we can say we need to double the height, which so it's based on a scaling factory, you can scale precise day. Sharing is slanting the image along exor by, so it feels you have like something like this, you can make it, you know, slanting. Yeah. So that's for different major issues.. That's for the processing take place. So they mentioned this is the second state, which is the core stage and why we need, this is like weekend enhance the age weekend, you know, we can maniplay the segmentation, no activity, and we have already discussed like the block like technicallyrine for the stuff and these are all, you know, some mathematically compression, but we don't have to buy about it. The library is doing it. We just want. Like you to make use of those functions already are la. Yeah, so next week we will die to feature detection and description. That is like one of the frosting. We are just like going to depth the bowling rejection like how we like that game. Like we saw for car injection, right? So something like that. So people see how the major direction of this picture is.