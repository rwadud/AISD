Texas to resolation, like the translation that alien canal, and how they, they, they, they, they, So this week, they call it very friendly. Um, Today he'll be covering the fundamental social news classification, see it, and we have, actually, if like, last week itself, with a diet or showing, um, input events, being pretty, uh, Yeah, and it has, it's been pretty, really good player, and then subsequent players, and then finally off player, right? So, coming there, I'm going to take them off. I think this thing also, and the data set preparation, and it has one decision, and then the data operation, and how to reside, CNN, and one of the different functions that we may be using in societies, in like application, most functions, and important algorithms, so like that complication, in multimite service, from how to play CNN, and phone issues and troubleshooting. Yeah. So So that's pretty much we really recording today. So in in add So you are the working times, right? So the area, is, is, is, is, is, is, is, is, is, and it's a subset of, uh, machinery, and I think it was newer network in many places. So last week, we have seen the layers of food, right? So we can have like multiple layers like Anusual layer, pulling layer, pulling layer, et cetera, a particular number of. So, I mean, it should be use, it will be very take place to actually some tasks, like, object index share, semantic segmentation. So do you know what Semani segmentation means? So, so that is information, you said, uh, task in hundred of the shell, uh, which classify each pixel in the image to a category, for example, uh, easier way to say is, um, if you if you ask the modern, um, if you ask a model to say, if this image are nearly cash or not. So the model can say, yeah, if it is an image, intention of the direction model, it can say, yeah, this image for days. I can. But for these advice in Malaysia, how it works is that, it tells exactly what whole pixels belong to that cat. Okay, so not only, uh, if it is personal or not, it can exactly like genuine, it's just belonging to that image of the cat. So that's why it's personality simulation. Yeah, so all these are actually in machine shell, home modes that can identify patterns and features present in the images. Okay, for actually, in this community, clearly, clearly. I'll be irritating, by which we make, the neural network, very like. Okay, so I hope you are familiar with this data now. We have... In the situation, because we may use a safe one driving. So we have one stage, which is being cut into the info layer and the input layer will convert the engine data in nurical data. And this data is being put to the next layer, which is the convolutional layer. So that's the layer where the model is for the network is extracting the teachers, right? So the use of conventional areas that we don't want every pixel in this image for training the movement. We just want what is needed, what is special, or what is important from the email zone. We create that into the emotional layer and the output of the traditional layer is called feature. So this feature hobbies right into the next layer, which is that. So including here, what happens is in Dow Sanders, the dimensionality of that feature. So it is that by, you know, depending on which mask pulling around it, but it's depending upon the size of the new giants. Okay, so from the pooling, um, there, the feature maps will be, um, I'm gliding there, um, taking more flat in, right? So 5 million planning. We can, um, gradually, you know, one year, um, so usually, the output of the layer the antidimensional. So we need to make it one dim ve that can be really good but more. Are they flatted better finitional later is where we do that Oh, yeah, like the magic habit. So it's So that's my during today. So what's why would not. So in my collector layers, um, When the, uh, the internet is being passed on, we do some other very collaboration and uh, we compute the loss. From the keyboarding into side, uh, using multiple high pressure of this. We will try to minimize the loss from that. minimize the laws at the they. But finally, what we previously, our modern player, right? So in our one layer, the number of neural surfaces, the number of classes. Okay, so you can see here we have like uh, a lot of classes because it's not really thought. And specifically half class, their sunset class, dog, and class cat, right? And you can see a problem from things like the class 4 for each class. So which class have highest task was that to be the prediction of that part? In this case, it should be classified. That should have a price to class. Otherwise it said wrong range, right? Yeah, so this is how the image classification is perfect. So within the most categorizing and levelling it into so much, we have the, um, for beginning, label the images with that classroom. Yeah, so it's talking about any, like, what kind of traditional it is doing and doing layer, and definitely kind of, which I want to be comfortable. So getting down on the purpose of the areolution putting and, you know. So, next place, they has a preparation. So, this is one of my, if I don't know, lightest, if you can image, classification. So we need to prepare our data in the alibis, what happens is the output or the more and more data. In that, appropri they are enough efficiently. So you can create a model, but it morely accurate or the performance won't be that thing. So we need to make sure that we prepare the data, the advice, later. So there are some techniques for that. So, uh, maybe most, I think the main area of uh, bearing the data is that we need to make sure that in our diverse set of images cannot be important, or in our data. Otherwise, the modern will be biased towards what you are providing that. dcent right. So we need to have a diverse in this example, we can see, we have like a different classes, right? stars should be coming. We need to, when you try your models, we need to provide diverse set of images. So that people won't be biased or if you won't be, you know, it can like better behaving any kind of like very emergency ideas because it already have seen that, right? Or he's trying to identify crossing eyes. So there is one technique which helps us to, you know, the, you know, the labelling, uh, So let's go annotation. Annotation means, it's the process of being dangerous. Okay, so you can say this image in this yeah image The tools, I school is labelled as schooler, they're going up. So each main is laboured with their classroom, right? So this process is called annotation. And this is formerly used for form, supervisedly area, because we know that there's long with this, right? So this is mainly used to for supervised learning. And we know that the quality and average of the equal data directly impacts the modest ability to behave to identity. So that's why they say they need to train a model with a good data set, which has a different set of majors. And yeah, for supervised learning, we can use techics like annotation too, label the image with in last week. Okay. So, our issue is one of the technique where we label the image, and there are different types of pre-processing techniques for preparing the images forcing. So, if your data is having images of different sizes, The input is not pricistent, right? So CNN would have to like, you know, what more is to take the features or to, you know, to perform on that kind of data. So if you make a professionally, hey, it's in our job or that, you know, we can prepare our data, they may not. we having only more size food, so we can preise itorm size. But I, or I, I, it's like you can normalize the pixel value in a range where you can slow to my leg neck. You know, if the intensity value, this is very drastically changing, and then it's not in my system equal to that CNN. So we can make it persistent by normalizing, you know, CO2 average. And also, for some of the techniques, we can convert, however, other images, there's eight. Now, any other colour spaces, beginning of what? How do you space? So while doing all these methods, we are making sure that we are providing consistent include that. See you. So by doing so, we can make it communication in that. So it's a, it's it will help the CHN work on it. So that's the reason why we we are giving that important to the Japanese process. Okay, so tell me question for you. Do you know that, right? The input data is divided into train validation of tests. So do you know why? why we need that? why we can't just use the cleaning. No, just training and testify any of these 3 classes. or 3 set of data. You need any idea. Any other? What happens if we just have training data? We don't know if our one is good for anything there, right? Because you can learn that data and just realize the value. Yeah. So usually. Yeah, so that's why before it pays off or everything. Okay. So why we have And we have validation. And So The standard 70 So this is the standard way of space, you know, but probably use the place, and take 80 percentage of the, you know, training, and 10 percentage for validation and 10 percentage for test. Okay, so this is the salad. And, uh, for this, mainly for training on one. Okay, so we have like majority of our input buildings, towards training the model, and through percentage for violating a 30 percentage work, just things. So again, when we, um, so what we do in Chinese is just, this is where the model. learns. So this is CRT, the model, right? So this is where the model is now. So what happens is being present is 80 percentage of uh, data to the model. Over and over again, and then it teeth, like, at least can learn the pattern from that data. So by passing the multiple types of how this is that you can, you know, It can 50 modern diameters on each eye pressure, so it can, like, you know, update or it can, um, actually, the 1st two, we think, but I mean, here's the more. What happens if we just have the rain and day I that because I said we repeatedly finating this data to the water right? So the water can memorize the value. So it can perform very well on any input that we need from this city. But if you keep, and they are from the, um, maybe I have seen data from the model or a new data, you cannot wear a phone because you just It's validation necessary. Because, yeah. Yeah, so that's why we are not how we get just having the training data. Okay, so next is violation access. So validation is making use for, you know, tuning the parameters. So this is where actually the tuning plan is for a flavour where everybody's like, um, yeah, the lady, right, the number of players, all those things can be defined by using the validation. And it also helped us to decide if I want to stop early. I mean, stop trading curly because, This is where we can always, um, parents are, take the training data, violation data. So if the accuracy of the model is high for training, you know, for validation, take us with some kind of stuff, because there is no point, is playing partner, because it would not perform better people. So the point, we should have the violation accuracy, higher than the frame, because violation is kind of regular and same area that we are giving to that mode, and I think should be able to be able very well to that. Right. So that's the reason why we need violation is highly represented to how violation is. And um, yeah, so. And this is where we can, we take the whole meeting as well. So over meeting, as I told you, it can work on very well on the training data, but it cannot personal, uh, paying for that, I say data. Okay. So that's why they need validation and it's just, just is different from validation because validation helps us too. But it's validation. Are you doing it multiple times? Yeah, this is a Fedex there. We are like, you know, I think he, um, I, I, I, I, I, doing more than once like you're not doing No, yeah, yeah. So, but the test is where? And the third set test, just is where you are actually validating the performance of your body. Okay. So this data is purely accessed to the model. I think we present this, we can, like, a few people know, like, people know. So depending on how your model, we can build this data. So that's the reason why we test data. So this is the idea way, but usually we have like a training actress and but it's recommended have our issues. Okay. So why many data open this is that? As I mentioned, we, it's always... Train the board, it has to just post as much as for planning. We need to train something, the diverse set of people data, right? Then only our model can be better, um, deal with available. But sometimes we don't have enough information because as I say, you know, sensual imagination. We use images as people, right? And sometimes we may not have the students in our, they have. So there is a way to link the, you know, the images. So in this image, like you have seen, we have the opportunity just to walk, from this just one single image, you can relate 10 or more than that by using some transformation techniques, like rotations, scaling, filtering, or being, et cetera. So if youJC right rotation plus 45 - 45. So acquiring these techniques, you will get multiple gauges from next single age. So you are actually expanding the data set, right? So if you have like a small data, so you can expand it by, you see, combination technique. So this process helps in reducing automating because we are already exposing the model to wide variety of features, as the annual, so we can better. You know, deal with the organization area. So it is maybe the scanner, more August, that includes that generalization. So we are training it with different features and, you know, the different scenarios that it can encounter it free. Okay, so population is happening, but it helps you to expand your opinion. And deciding, the CLF architecture. So there should be, like, you know, of course, we are most of the cases we are known designing it from a scratch, usually taking a self-state of the art in the world. So, you know, the what is like, image, like, or part of our language is already available. But in case, like if you entertain a, like, you know, RAK specialist or something, you are right, you're all single from scratch part would be the, you know, clean acceleration that you have to keep in mind or is there any a CLN? So you have to think about a number of layers, type of layers, type of emotional, like, like, the, right? And their parameters, like filter size, stride, activation, function. You know this t, right? The filter sizes, stripes. Right, you remember? The steps size, which, which the filter is moving? It's not study based, right? Okay, so all these are the key points that mean, we do consider by deciding SEM. So there is no perfect formula. Like, I cannot say, yeah, for your, more like, if you ask me, like, hey, I wanted to, there are such a model, like how much unusually I should use. No one can tell you a perfect formula about that. But there are subjects like for for it, like, you know, lost game, or, you know, uh, small, small, you know, just leaving from 5 to chairs. But for any, they're actually more like, you know, as they know something, you can have a 50 to, 500 or 50, 200 years. Depending upon how far this year, more than 50, or you have image data, maybe, or data, maybe. So depending on how homeless your application, you can decide how many layers and what only. Sometimes we just need one solution, one way, one way connected. It's a simple issue, but sometimes it's not that, it's not that enough, right? So we need to have multip% of convolution, I think it's an option. And another thing is that always, the number of theatres using the, 1st few days, it is, for example, like, If we have multiple revolutional layers, the number of layers will be, or maybe the 1st day we will have to 16, let's say, 32, like 64 impose like that. So all these, in the 1st few years, we are travelling the similar features. So the more deeper they go to the deeper, the more complex values will be expanded, for that really more filters, right? So the number of filters, in each layer may be more when you go down the, yeah, down the anything. So that's either key point that. Yeah, so as a mention, the architecture should match with the compensity of the task. Even it worked for more complex tasks and consideration of combinational efficiency and yeah. Other thing is communication efficiency, you, maybe your model is medium, and you might have choosing, you know, very simple architecture, then it is communication, either your model cannot handle that. So you need no computational power, and no layers to deal with that kind of stuff. So you need to keep all these considerations, the number of players, types of players, their parameters, all these things should be, lifting right, while deciding it is so happy. I mean, repeating again, there is no perfect formula, but depending upon the formats, we willing to decide. It's always a trial, there, whether you can't fix it. So we have We talked about it last week. The application function is a function that Indians is ending on fire, so that means... In the vocabulary, you know that we found in number of, you know, Euros, right? So we have a, let's say, So there. And there's a lot, there's a lot. So, you know, in one place, connected to the previous thing, like, soul sleep, there is a connection between all the neurons and that, genuine. So what happens is that we have an equal data here. it should be trans here here. so to this day this there is a job. Okay, sometimes we don't need all the new ones to translate to the next layer because they're not needed information. Maybe it said, you know, the foreigner, which is not maybe a background, so we don't need that for further processing. We can ignore it. So one decides that is activation function. So some tours are not needed, so it can be even solid. It's even a more output of that. And tuition function. So activation function and' getting upon the output. In the application function, then you are inspired. By the means, it will vulnerable to the, you know, over output of that. Yeah. And another point is, animation fashion, introduces lonely VAD. So I mentioned last week, if our model is scenia, just like it perfects the C + wire or something, you know. So if you if you know that if you want, this will be down, you do this with your episode. It's just a linear, right? So it cannot lead to focus, so like patterns, like, you know, images offers or something like that. In that kind of scare, if we need to introduce some non-linearity to our notice for this, we can use that information. Yeah. So, uh, basically, in New Orleans, we waited some of it is, so you always have a way. And when it's in point of time, we added by SOI, actually, not just as class, last week, you cannot go to the slide. I'm just asking you, by the way, 10 miles is the way. And these are the only, they are having elevators in that area. Okay. Today, I've been, I have to say, I have weight and advice. So this is the, you know, this is part each you are making happy. So, weight, magnified by setting one, that's advice. And we gave this to where an animation function. Can you really of this activation funion, just neural is fine. Okay, so the action actually get of types Yeah, that may be. same now. So there are different territories. Singapore is, um, one of the popular activation function, which is used for validate classification, and it always ranges between 0 and one. And you can see 0 and more. And towards the pages, it's not, you know, if you won't learn to be. So it's going to be, you know, some kind of like stay stable, right? So that's for vanishing, they didn't program. It has to actually very important, but still we use this way for the family musket issue. And it's our money. You know, there's another country between the rates, you also, one. And it's, you mainly used to for automobile applications. So, um, if it is great, I mean, if in your money, you can say that, hey, this class found it is higher, you can assay in that complication. let's say that we have the same of this class. So this is mainly used to work. Finally, classification. And there are other, like, damage. Carriages, um, you know, it has more rates. The previous one have the experience, you know, one, is like how minus one, the white space, we are including minus values as well. Okay, minus one and. So it, more balanced powerful, which is sent to 0 and uh, This is more than differential activation function, and this one, did you notice that? This one also have the alien, yeah, polishing getting soccer because towards the edges, it's going most steadily. It's not no easy for to, like, similar to the previous one. And it's even used to work, dealing with negative input facts. And then part is very popular, but you find near it. So this part, we take only valleys, which are a greater that's in all other nodes, the artwork, is minus five. We just keep in silent if this later, that's your, let's say, to just carry on. Then maybe say that we have this new candy fine. Okay. So, um, yeah, so this is the great, so you want to infinity. So it takes away the possibly bad, from zero, because it's not, totally infinity. Um, yeah, so why keeping positive wise and takes me from most of it. So it could be... Unfortunately, we are not committing a lot of, you know, like the others too. But, yeah, so it can help us feel better, release that, or, you know, and here there is no, you know, imaginary because it was different, right? So in the India, you know, towards the post suicide, they post English. It's usually a very used to for efficiency, and in a hidden layer, so feel forward. So it's not that commonly easy not to play, but in the Italy is. Okay. Other than concept, um, in... Nurul advertis laws function. So as it's 8, it's a mission of like a loss Las We haven't registered, right? We know that this sequel, we have this output, but what we get is different from that. we take a difference between that. Okay, so let's say we are expecting how to buy, but why do you know is my cash, then we take just secrets and this is for the loss. Okay. Loss fashion isn't mathematicification that measure how well they modest tradition match the true outcome. So it can't leave, loss is more, which means that the difference is more. So it's not actually matching at all, right? But if the loss is less, it means that it closely matches. or, you know, giving yourself preparation. So you try to find the difference between what a prediction and. Yeah, so this, um, most, uh, friendly alcoholic layer is cost function. And based on this procession, we can, back up again, and we can, you know, add just the base and the 100 parameters to the neighbourhood. So and maybe get the name of lawsuit, right? So this is our thought, that we should get the minimum loss. So for that, we need to use loss functions. They're normally useless, and those cultures are. We require error, cross and focus. The other is one type of technique, and most entropy, and most entropy, so we have binary health, categorical. categoory for multiglass classification. By the way, there are since 98. It's called, by the way, classification. So you can So this is our idea of like most contin. Our law is to reduce the loss of our debt. So weute the loss for came, right? For each digression, we will come here with this loss, until we get the name up, we will see that then. destruction. Okay, so I mentioned a whole lot, right? So there should be a different way to come to the Los Vegas spreader, and there's other, and there's like gradient design. Ingredient is that it's an optimization algorithm actually, if we need to, in this account, like we are trying to minimize the loss. Okay, so how we do is that if we when we calculate the gradient at a current position, if it is, you know, if we if it force towards the left, what we do is we move it, we move that close towards the right direction. Okay, so if it was pouring from the light side, we move it to the left side. Okay, that's not where they play in, most. Okay, so depending upon the grading position, we can compute the lower standard optimal position by spending about. This is our optimal position. Okay, so our goal is to reach this way ongoing. Right. So when the model is trained, our model is to have the minimum loss, right? For that, like when they commute a loss, if it is going on the left side, it should move towards the right side to get this point, right? You thought the 45s are... They need a wage here. We are here. And if we move to that level. Okay, to reach this on human health service will be that. Okay, my phone. So that's the reason why we communicating. And so this is one of the technique for, you know, currently seeing that, knows in the, uh, later. So, this is the, um, CNN. So this is the, where it's very important at all. So that propagation is not our technical algorithm, that helps you to add just the weights and parameters, and you can optimize your, you know, parameters and if we give you the minimum loss. And all the functions which I mentioned earlier, like, you know, the loss function, the variant is that all these are used in back propagation. So this is actually, you know, a higher level and low level, all these things are happening in the construction. The gradient isn't all these days are under the foot. It's happening and the back propagation, they will help us to minimize it. So for a model, what happens is that we present the input to the model, we pass the input to different legs, right? the little like unusional food be connected. And while the data is being passed through this model, we do some calculations and in our player, we get the loss. So what we get in the end is the loss. And since we have the loss or error, like, you know, since we can say that there are photos, since we have that error or laws, in our full year, our goal is to minimize it. Right? For that, we need we need to use some technique, right? So for that, we use that propagation and going up to propagate that there are back to the, you know, from uh, so if it this is your own layer, if we propagate back to the layer before that, then to the layer, before that. So I'm really brings this in point. And then I just won't wait sadly bias. And we... around them for that, particular, you know, and just went, well, let's somewhere, like, if this is still being correct, Then again, we drive back, propagate this error, and then we get, they give up, there are here, right? So this is the idea of where from vacation. It happens only in doing training. Okay, so the vacation company is only doing really, not during the validation of the states, not having. We don't need that, right? We need private propagation, only you, I'm just the weights and, you know, the parameters, right? Weights and bias to get the minimum laws. So that's happening only during the training. During the testing, we are just pursuing the input to see how the model can take the British. we are not training or, we are not addressing any weight or anything. So this is having only during the training back vacation and basic step is because we feed the sample to the network. And calculating the inspired error. For usually for supervised the learning, we know that, right? Our output will be like this. So this is like, yes, make me know that if you belong to the class gap, right? So we expect that output. From the expected output, we can compare it with what we want. So that will just have to calculate it in square error. And we can't play the eruption for each hour, so for each, or to give an interest to this, right? And then I'm treating it hardly, yes, I think, from, uh, we commute their thing for each neuron. So we represent how much this neuro is contributing to this era. Okay. And then it from against that, like when you need to that subsequent, like, you know, previous lengths. Yeah, and while it's going, then we apply a delta road, and just the weight, and we, again, uses like feet forward, then that works. So being forward means it's the simple way, like we are getting the input, which is then putting to the power, like, you know, inner layers, and finally we get on, this process is called a feel for it, like, you know, um, or forward propagation. Okay, foreign propagation is nothing, but like you are feeling your infant to the Indian player, which is then given to the inner player, and finally being like out to layer, and we do the calculation to get the... So this is playing for a propagation. And in the bad propagation for me, take that here, and we commute the airplane for each new rock. And then we hydrangically hardware the aircraft, then hitter layers. Okay, and we add just the weight and do it again. Again, we, like, the foreign propagation, we can be error, we know which, when we come here, and that, we can do it until we get the name of. Okay. So this is how we, uh, we are feeding the sandwiches and it our 1st step. So we know that our, let's say that this is a binary classification, so in the binary classification, we have just to order, right? So either it should be a 0 or one, right? Finish one, it means that the remains below to that class. 0 means, it's not belonging to that class. So you can say, like, it could be 0, this belongs to that passport, then depending upon the information, you, you want to make for your product. So we have like 0 and one as them expected out. That's what we are expecting. Okay. You can say. Let's say we have, we could, we own, we have wires 2, 5, one. And that's the, yes, you know, and then we have one live 2, and live three. And just one person, let's say, the bias. So what we do is we take the A 0 and then we multiply it with a weight and then, you know, so all those things like adding a wise and transmission function. And then finally, what we get, they said, 0, 0, what is the output layer? So now put layer, you can see only 2 euros because there are put number of euros in the number of classes, right? So in binary classification we have just 2 classes. So we have 2 neurons in the hardoon layers. Okay, so let's say that we got out of this point, 2 and .49. So this is not what we expected, but that is what we bought in the 1st time pressure. So what we do, how we need to talk about the health care, right? How do we know the error of death? We? Take the difference between expected and then, actually. Okay. So that's the 2nd step. We calculate the be squared better. So this is the equation for commuting the means square error. So YI, minus OI, the 4 square, you see that. So we have the expanded one. Oh, which is one, which is one. And we take it. Okay, so, finally, this is .0 and 42601. Okay, so that is the corrective for this final layer three, which is the output layer. Okay, so that match is that there are a pay for each new, in that pay. Okay. So, I, maybe, we, we pass this, tell, do that. Uh, you know, the layers of the, previous layers. Next one is, um, family, out for their cars. Yeah, so. So I told you, like, this is the output element. This is the main square colour, right? This is the, uh, you know, the output elector. For, for this, we have a different equation, like this, okay, into one minus 14, YKM is okay. So for each neuron in the output, we will compute this value. Okay, comply this equation and we compute this value, and partly get as output easily, and then pay for this output player free. Okay, after applying this equation, we will get. The output perative for that. And the 4th is the base, calculate the hidden length. So once we've got the output layer, we come again, is that the 10 layers. Okay. So you don't have to buyart to go I think just I want to make sure that you understand what's happening in the back location. Indeed, we can see 10, 30, 10, 3, one, which is hybrid, right? So that is the output. And then we need to propagate that back to the previous day. So we can see Del 2 one, right? So these are connected. And you can see, this is where a 2 layer one. So layer 2, then 2 my instrument will do the previous layer, which is the layer one. So once a main idea is that whatever we have in the play, we are propagating that layer too, and from layer 2 back to there. Okay, so that's why we calling us that propagation. Yeah, from very, like, uh, producing this pathmaling equation. too. And then it places all the layers or all the universe in that, in a letter. After computing, all the error styles. For each neuron in the network, people apply the delta. So like this. Then you guys, like on each weight, is government a light. So after applying this equation, usually it's a high. So the value that needs to be added to each weight, each way. So this is capacitor by getting by, when you want to, et cetera. So if we get a delta,. So Del W. So how to comeute this cell level is this question is week. Okay, so we will have you, the delta, W, for each of the collection data, for each connection in the network. Once we get that delta value, we apply that to each layer. So I say mention, because we have the delta identified for H, we will add that to that, correct? that we're going to pay. So that's probably just the ways. Okay, okay. So after I just did this, we again, do the same process, you know, before it, again, we advert, like, you know, in my competition. So this is the idea behind back competition. So, basically, learning this is being made up, sounded to the network, and then after the main squired error, I'll play the error game of each, output neural, and I try to really calculate the error jam in the federal layers, and we apply the delta one. And finally, we add just the weights. Okay. After you adjust the new weights, you run it again to make sure it's good or no? Yeah, so that's how we do the training, right? So this is just one nitration. We need to do a high question until we get the minimum. Close. If we have, like, continuously... That's the... Then you will learn your, you have to actually try your, so you will get... Um, do you think five minutes, right? So he types the road is JD, which is a casting base, he said, and he's simple and empty. And Adam is the other one, which is known for adaptive is to different problems. So this is very popular. And, um, I mean, here, which I said, it will be interesting to get from. Again, it's up to you, but Apple is a recommended one. And I is probably the other optimizer, which is my biggest thing. Okay, the job, there's also optimize the affects, the speed and quality of training because if you select the problem, the training will be faster and it won't be a potentially heavy. Again, it's another factory new person. when you are, you know, you are deciding, you see in and out. So you can always serve so, like, which one can be used for for, you know, training there, you need to classification, size, and you can, but. But most common money, SDD, Adam, Adam's mostly salad, just like, you know, because they know, they aren't safe or comparing optimizers. Um, Trying to see it, that's that much back. So I have already told you, the best family seems to have, like, trained validation, and I'm just thinking that it's not military, but it's also the best practice, okay? And as I mentioned earlier, the best we base that, we should have, you know, high advocacy for validation data and compared to the accuracy of the training data. So we should always have high access, and we, you know, laws for validation data. Okay. Yeah, compared to the training. So that's how the Japanese are present. I'm trying to see the indoor, each guys in the way. It's the custard based, the way each guys to wait, and then they provide complication for their provocation. As I mentioned, it's very good, just like, you know, from the age, they include the instructor, I mean, put that output. And finally, they get that, yeah, of the, like, expired at a broad process, you know, it's very important, yeah, but actually used for calculating them. And then, um, you know, uh, we have like the loss and we look at that location. The calculate gradius and finally, depending upon the, you know, the optimizer we use, we will adjust the weights. So this is the basic idea. So writing a CNN stuff, please, fascination is the way that the permit propagation, you get the permission. And that way the loss, we do the bad propagation, you calculate the training. And finally, we use optimizers too, purchase the weight and link in the neighbourhoods. So the best practice include using a validation set.ain a as practice use validation. It's not valid great. Most of the cases that people tend to use training and test only, but the best practice is to use the validation. So it helps us to, you know, uh, uh, do the hyperparameter, uh, like the parameters that can be contested, you know, uh, that can be initialized, like the lady grade, English is the value, then the number of players, all these are, you know, hyper parameters that we initialized at the beginning before the training. And during the training, some of the algorithm can change it. You know, depending upon like if it is not suitable, it can change. Okay, so these are the hyper parameters, which are the parameters we initially actually before the training. Okay, and bias and weight other, learnable diameters. So their learn has been trained. Yeah. So, we apply at least talking to freeway over 15. Okay, if you train a lot, it can or it doesn't become too good to the training data, right? So how we decide to stop training is that by noting the accuracy. So if we see that the accuracy of the body action set is less than training, so it's an indication that we are training is not cognitive, they're actually changes. Right? So that's what it is, like, applying entirely stopping to prevent the overfilling. Okay, if you keyboard training, It will overfit through that. Yeah. And another best practice is that periodically save your work. So, you know, periodically saving the model stay. So it's called, like, modern state, you can do the more space for recovery. So if, you know, the sheets, right? so anything can happen any time. So you don't have to start the training from the scratch if something happened. So you can save the motor state. So that is some incurring pressure, some interruption happens. Um, it will be saved and when it resumes, you can continue from where people come from. So that's part of another was practice. Um, So either one is more important training process to figuring like laws and accuracy, both on training and validations. And as I mentioned, what matters is the loss and accuracy or training and pilotation system. Okay. Yeah, so. It helps in understanding model performance and making, this is the adjustment. If we feel like, you know, the model access is too good on training, but it's getting increased on interiority for the validation, which means it's not going in a good direction, right? We can stop it. But on the other side, if the actress is too good for the validation and paladation than the training, it makes it's a, you know, business food, it's a good one. Okay, so, again, understanding overfeeding. So you already understand what automating is, right? It's becoming too good for the training data. So we can identify or It can be, like, very good performance on the training data, but it can be, very bad for performance stuff. And you are working fancy data, it does data. Okay, so that's what our data is. This is how, um, you know, um, an example of model loss. So the loss for the training data is very introduced, but the loss for the validation is going parriage means it's not going in a good directions to ensure for our meeting, right? Because the loss is getting minimum, really more. you know, the training for that. Yeah. So opportunity offers when they see it and want to learn some training data too well, including its noise and obviously even you can learn the noise from the data and it keep more performance on new or unseen data, the test data. So, um, it happens usually normally complex models with too many parameters. So we have like too many parameters so you can have it. So the symptoms of more feeding include much higher accuracy on the training data compared to paradation data. getting down that It was like, no? If the address is too high on the training data compared to variation inmates, the model is over to me. Okay. So, um, we can use some of these packages to prevent over the day. Um, one of the days, use dropout layers. So as I know, not all the neurons are needed, right? So we can randomly choose some of the new rods or, you know, some of the layers, so if it has like any number of layers, you can decide to, you know, mute some of the layers. So that's what it's called to walk out layers and you can randomly choose each layer too. you know, a job. And in one direction, you can drop this there in the next time, Russian, you can use this one, but you, you know, drop this one. So it's some random one. The benefit is that they, you know, the model can learn all the, you know, variations and the complexity from the from the input. So it's not just training on the same neurons, you know, sometimes it's missing some of the new ones. So you can identify that patent and with the next type question, another player is drop. So we will learn that pattern. So, you know, by doing deactivating sudden nuros during training, it can, you know, prevent the code application of features. Otherwise it will memorize the patterns. Right? So by dropping something randomly, we are not giving a chance to the model to buy hardly imagine. Okay. Yeah, so then there are methods like, you know, uh, regularization methods, like, you know, uh, so just going in depth what is, um, within some way, but there are regularization methods that can help us too. reduce the opportunity. And other ways to expand your data set by your condition. As I mentioned, if you have just small data said, you can always expand it by applying some transformation, like rotation, cheers, eating, you sensing, you know. So you can also spend the data set to provide more varied training examples. So by doing so, you are training the model with different variation of different scenarios, right? So we are training the model, you have to handle all those real good stuff. Let's simplify the body by redacing the number of waves. Again, there's a cash depending upon the complexity of your modelling, having to save the number, you cannot reduce the number of layers at all, but depending upon like how much you can reduce. It's better use, as less as possible. And early stopping falls raining, when performance on a violation says starts to be great. In other ways, like you mentioned, when we do, you know, performance analysis by computing the accuracy of validation and writing, then if the accuracy of the validation is degrading, then it's time to speak. So these are sometimes standard, is that help us do, uh, raise the overpid, you know, some extent. So hardware resources for deep learning, you know, that we have like different, so starting from CPU, now we have like CPU, TPU, and so on, right? So for smaller operation, we can UCVs but medium it is like very a you can listen to you. Okay. So the implant requires significant communication to shops. It's not a super class, like it's being with a complex standard, I think, that needs to be committedly heavy sometimes. And for that, we need resources, communational resources. So see, meal with people forced adversity, but slower from this class, and GPS with 1000s, of course, I did, I did it for the parallel property. It's something that you really sometimes being. For our taxing assignments, we can do with CPU, but in your lap file, you can introduce GPU because you are training, you are not doing anything. So we can do that. It is more computational problem. Okay. And TV is besides specifically for neural info operations. So you know that neural network is like dealing with access Initially, like, maybe, and depending upon the size of the data, so maybe, it can be more progress. so I can to be in that we need to use. So they provide faster commutation and again. It's always of the resource can be fat, they are procy and this is. What's in TPU? Like, I know, I know what the others are, but what's a TV? TV is like in the game. You know, it's like, you know, you could have capacity for the package processing. Um, if I can double check, but this is more powerful than... Is it something that fits a computer or is it? It's something like, you know, uh, for example, in Amazon, you can, you can, you know, servers, you can, you can. Okay, okay. Yeah. Yes, exactly. Yes. Yeah. No, TPU, I think, but GPU, and CPU, you're working. No, TPU, maybe, I, I'm... I think TV is also available available right? Yeah, TV also, yeah, TV also, yeah. But we, I think TV will be about that as a show. Yeah, so TP is the most powerful one. you know, depending about how profess your application is you can choose. So the choice of this hardware can significantly impact the training can, if you are using like more power, if you can finish the training hotel, I'm still remember, like, uh, lasting bats, because some of this food is hard to money for overnights, or, like, you know, 2 days, uh, depending upon their, you know, life. Yeah, so these are done. Some kind of hardware considerations that we need to keep in mind, why just... Yeah, so as I mentioned, uh, we are gonna make the exercise to Sydney resource, right? But sometimes to do the post issues, I know, we won't be able to use, you know, very high-end processors. So there can be some of the techniques that we can use to reduce the computational complexity of the model. So you can even use the TV, like GP Instant of TV, because like we are using some of the database, like pruning, puning base, we are removing some red and then nurse. Sometimes in the network, we have some pretended noodles, you know, so we don't want pretending noodles, right? So we can even like take one of the microphone, they buy it. So by doing so, you are within reducing the popular city, paid by half or eight, depending upon how much the noise is happening. So that's the technique. So having that said, I have a, you know, linked to the acidares, bacteria session about hooding and poding session, so you can wait, wait for understanding it more. but just for your awareness. So this is one of the optimization techniques, I mean, you must for, you know, producing the policy computation about. Okay, so either place one decision. So this is how we reduce the position of the j. So, you know, we are dealing with numbers by variously mean like we have, we are dealing with the numbers, right? When we say Euros, we are looking at numbers, right? Because images have pixels, which have values, right? And we are apply our all these are happening in the mathematic education. So we are dealing with the order. and the position of the number matters. So you can reduce the position by using partyStision matter. And by using, like, additional appetite to, like, 5 years of, by choosing uh, already well not tested and, you know, trusted, and, like, it's available. A lot of state of the art. Not as valuable. So, if you want these, you know, just, you know, the R one, but, like, you know, you can do that depending upon your recognition. Okay, so by using the efficient architecture. So they are already for, you know, they're already done over these techniques and number of layers are, you know, the power of development and the number of parameters there is, like, your humour. So they are already, you know, they have the architecture, which is already helping us to reduce a lot of computational work. So they take take care of a lot of stuff that we don't have to worry something like that. So if you can use some other statements, you know, as well, this is one of the, uh, more recent key resources organization. For example, like, um, another advice of, you see, the state of, they are, um, you know, how many pictures is that, it can be, uh, it's like a bad thing. So you can make yourself eat in developing applications that needs to running over because things like that. For such devices, we cannot compromise the accommodational complexity, right? We are not happy if our competition is loading for a long time, right? So everybody wants a very to be there, social should be very quick. So we can make you some the existing architectures, which could help us to, yeah, achieve the task way faster. So you can teach that one. So the one of the key difficulty in vacation is that, like, investigation, we deal with majors and videos. So it definitely takes a lot of, you know, computational capacity and resource power as well. So our, you know, the research is being carried out. We were now to minimize the use of, you know, resources, but to provide it faster and accurate, so you should. So for that, like, you can use, if it's like this grooming, money session, like you say, apple, build it, it's... So the future of, uh, this will be something like, we can indicate here and with other deep leading techniques. So, as I mentioned, there are, like, a feeling is one of the part of it, and we have techniques like in the international encampment processing, and R&M, which is better in neural network. So we can combine our CNN with base model to get, you know, different, you know, a new model which can provide more than that, right? So, um, that's some of the scope of the CNN, like you can compare it with other people, uh, laying the tools, uh, including techniques as well. For example, if you in the game, see it in with preference neural networks, you can perform video fascification because Arden is very popular for Europe. So the video transportation. And natural language processing modes, what it can do is, since it is good at, you know, the language processing, the captions in the English on the media candidate, you know, can be very understood easily or can provide that. So by comparing different techniques, you can create more sophisticated or more, you know, better systems or applications. So this is just an example of using the combination of CNN with other data. So if you use Ireland, you can perform video classification and major classification. Then for, like, comparing intendedly, you can create, you know, forests, uh, for immediately cashing, uh, et cetera. And these integrations are offered multimodal learning and, you know, the main idea of company is that CNN is good at creating visual data, right? So why, and then we can be the language, but the scene it can be the English part, right? So when we combine that, maybe get a better obligation. Yeah, so as the field of AI is the morning. This form of vegetation is also like glowing and because we can integrate the technology. Yeah, so troubleshooting and how many issues it's here. Us we have years. One of the major issues over the days, so I'm order the company looking for their training data, but if they cannot take the vaccine data. And another, but if another, maybe, another, maybe, you cannot learn at all. So it's not going to be worse than a matter of prediction. So if you give the info, you just say, like, this is the characters, the boxes, some bad information. So that not is not good at all. So I don't think that pathologies is intended to preverse to a particular class. So that is kind of this problem. Then strategies to publishing, including, I just think they're learning, right? So, learning rate is a hyper, but everybody can, you know, assist it. Initially, you need to set it, then later, you can access it, so, learning rate. I'm modifying the network acriccture. So maybe if you are using your own, you can replace it with state of the art, architecture or, you know, so you can make adjustment to the number of layers or the number of parameters that you will use. Then batch normalization and drawout. So dropout fees, university can clean out some of the players in the, in the, you know, player, right? So all this technique, um, can have to try to shoot. So after 2 applying promos, if we take a performance in tricks to see how it is going, and if it is going, yes, say that we have to stay before. Yeah, so this are some of the troubleshooting. And, um, okay, other one is that, um, The training data that we use is very Korean, right? So we need to make sure that the other divers set off can just never egg ass set that we are cleaning out little bit And we need to regularly monitor the performance of World War. So if we see that of more performformananceces beh intority on the variation set or the system set, which makes that this canab be not it right Okay. Yeah, so these are some lovely chocolate shooting. I'll see you in for me. Yeah, so underfeitings, they mentioned, I don't think it means it's the most common that you can create, because it cannot share actually anything from the data. So, uh, we can actually catch on the avalanche of the data, so it can be understood by this in the modern conversation. So when overfitting stays, you know, you can reduce the, you know, training on, like you can, um, don't try the model a lot. So what we need to say that, right? But for other people, for instance, it's like we need to increase the modern complexity, depending upon, you know, adding more layers on, because it cannot, with what we have now, you cannot AI, the patents in the data. So that's why it is having a notification, right? Because the current architecture is not good enough. So what we need to do is we are more layers, so we do not see. so that it can learn correct. diverse, you know, no data. So if we are presenting more data to the network so that it can learn. then train for lower view. So, um, we, there be the training that we did this morning, so we need to train for. Lower duration, or use more powerful and diverse speech transtraction details. So the pollution techniques or, you know, the painters that we have wear is not really, so we need to, the time we change them. And another approach to dream is in the data previous. So data pre-processing means like annotation or, you know, documentation or, you know, otherwise it's like normalizing the value of precise, you know, like exercise. So whatever we did. Maybe it's not that good enough. So, really is it that kind of break was? Um, yeah, so. These are some of the key noise that you need to keep in mind if your body is showing under a feeding, uh, you know, obviously that's a few months, not giving any food results and all. So, praying for our way, try to change the architecture, or by adding more layers of buying more views, more how, you know, data, it doesn't between them. Yeah, or bring the, data, bring the,