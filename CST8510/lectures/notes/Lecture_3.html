<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Feature Engineering, Missing Values &amp; Feature Selection â€” Study Notes</title>
<style>
  :root {
    --accent-blue: #2563eb;
    --accent-green: #16a34a;
    --accent-orange: #ea580c;
    --accent-red: #dc2626;
    --accent-purple: #7c3aed;
    --accent-teal: #0d9488;
    --bg: #ffffff;
    --text: #1e293b;
    --text-light: #64748b;
    --border: #e2e8f0;
    --card-bg: #f8fafc;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
    color: var(--text);
    background: var(--bg);
    line-height: 1.7;
    padding: 2rem 1rem;
  }

  .container { max-width: 960px; margin: 0 auto; }

  /* Header */
  header {
    text-align: center;
    margin-bottom: 2.5rem;
    padding-bottom: 2rem;
    border-bottom: 3px solid var(--accent-blue);
  }
  header h1 { font-size: 2rem; color: var(--accent-blue); margin-bottom: 0.25rem; }
  header .subtitle { font-size: 1.15rem; color: var(--text-light); margin-bottom: 0.25rem; }
  header .course { font-size: 0.95rem; color: var(--accent-purple); font-weight: 600; }

  /* Table of Contents */
  .toc {
    background: var(--card-bg);
    border: 1px solid var(--border);
    border-radius: 10px;
    padding: 1.5rem 2rem;
    margin-bottom: 2.5rem;
  }
  .toc h2 { font-size: 1.25rem; margin-bottom: 0.75rem; color: var(--accent-blue); }
  .toc ol { padding-left: 1.25rem; }
  .toc li { margin-bottom: 0.35rem; }
  .toc a { color: var(--accent-blue); text-decoration: none; }
  .toc a:hover { text-decoration: underline; }

  /* Sections */
  section { margin-bottom: 2.5rem; }
  h2 {
    font-size: 1.5rem;
    color: var(--accent-blue);
    border-bottom: 2px solid var(--border);
    padding-bottom: 0.4rem;
    margin-bottom: 1rem;
  }
  h3 { font-size: 1.15rem; color: var(--text); margin: 1.25rem 0 0.5rem; }
  p { margin-bottom: 0.75rem; }

  /* Cards */
  .card {
    border-left: 4px solid var(--accent-blue);
    background: var(--card-bg);
    padding: 1rem 1.25rem;
    border-radius: 0 8px 8px 0;
    margin-bottom: 1rem;
  }
  .card.green { border-left-color: var(--accent-green); }
  .card.orange { border-left-color: var(--accent-orange); }
  .card.red { border-left-color: var(--accent-red); }
  .card.purple { border-left-color: var(--accent-purple); }
  .card.teal { border-left-color: var(--accent-teal); }
  .card strong { display: block; margin-bottom: 0.3rem; }

  /* Grid */
  .grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(270px, 1fr));
    gap: 1rem;
    margin-bottom: 1rem;
  }
  .grid .card { margin-bottom: 0; }

  /* Tables */
  table {
    width: 100%;
    border-collapse: collapse;
    margin-bottom: 1rem;
    font-size: 0.95rem;
  }
  th, td { padding: 0.6rem 0.85rem; text-align: left; border: 1px solid var(--border); }
  th { background: var(--accent-blue); color: #fff; font-weight: 600; }
  th.green { background: var(--accent-green); }
  th.purple { background: var(--accent-purple); }
  th.teal { background: var(--accent-teal); }
  th.orange { background: var(--accent-orange); }
  th.red { background: var(--accent-red); }
  tr:nth-child(even) { background: var(--card-bg); }

  /* Highlight Box */
  .highlight {
    background: #fef9c3;
    border: 1px solid #facc15;
    border-radius: 8px;
    padding: 1rem 1.25rem;
    margin-bottom: 1rem;
  }
  .highlight::before { content: "Note: "; font-weight: 700; }

  /* Badge */
  .badge {
    display: inline-block;
    padding: 0.15rem 0.65rem;
    border-radius: 999px;
    font-size: 0.8rem;
    font-weight: 600;
    color: #fff;
    margin-right: 0.35rem;
    vertical-align: middle;
  }
  .badge.blue { background: var(--accent-blue); }
  .badge.green { background: var(--accent-green); }
  .badge.orange { background: var(--accent-orange); }
  .badge.red { background: var(--accent-red); }
  .badge.purple { background: var(--accent-purple); }
  .badge.teal { background: var(--accent-teal); }

  /* Term */
  .term {
    background: #dbeafe;
    padding: 0.1rem 0.45rem;
    border-radius: 4px;
    font-weight: 600;
    white-space: nowrap;
  }

  /* Flowchart */
  .flowchart {
    display: flex;
    align-items: center;
    flex-wrap: wrap;
    gap: 0.25rem;
    margin-bottom: 1rem;
    font-size: 0.92rem;
  }
  .flow-step {
    background: var(--accent-blue);
    color: #fff;
    padding: 0.5rem 1rem;
    border-radius: 8px;
    text-align: center;
    font-weight: 500;
  }
  .flow-step.green { background: var(--accent-green); }
  .flow-step.purple { background: var(--accent-purple); }
  .flow-step.teal { background: var(--accent-teal); }
  .flow-step.orange { background: var(--accent-orange); }
  .flow-step.red { background: var(--accent-red); }
  .flow-arrow { font-size: 1.3rem; color: var(--text-light); padding: 0 0.15rem; }

  /* Progress bars */
  .score-bar-container { margin-bottom: 0.75rem; }
  .score-label { font-size: 0.9rem; margin-bottom: 0.2rem; font-weight: 600; }
  .score-bar {
    height: 22px;
    background: #e2e8f0;
    border-radius: 999px;
    overflow: hidden;
  }
  .score-fill {
    height: 100%;
    border-radius: 999px;
    display: flex;
    align-items: center;
    padding-left: 0.6rem;
    font-size: 0.78rem;
    color: #fff;
    font-weight: 600;
  }

  /* SVG containers */
  .diagram { text-align: center; margin: 1.25rem 0; }
  .diagram svg { max-width: 100%; height: auto; }

  /* Responsive */
  @media (max-width: 640px) {
    header h1 { font-size: 1.5rem; }
    .grid { grid-template-columns: 1fr; }
    .flowchart { flex-direction: column; align-items: stretch; text-align: center; }
    .flow-arrow { transform: rotate(90deg); text-align: center; }
    table { font-size: 0.82rem; }
    th, td { padding: 0.4rem 0.5rem; }
  }
</style>
</head>
<body>
<div class="container">

<!-- HEADER -->
<header>
  <h1>Feature Engineering, Missing Values &amp; Feature Selection</h1>
  <div class="subtitle">Deep Learning Features, Text Preprocessing, Embeddings, Data Leakage &amp; Shapley Values</div>
  <div class="course">CST8510 &mdash; Applied Machine Learning</div>
</header>

<!-- TABLE OF CONTENTS -->
<nav class="toc">
  <h2>Table of Contents</h2>
  <ol>
    <li><a href="#s1">Deep Learning &amp; Automatic Feature Creation</a></li>
    <li><a href="#s2">Why Feature Engineering Is Still Needed</a></li>
    <li><a href="#s3">Traditional Text Preprocessing</a></li>
    <li><a href="#s4">Missing Value Treatment</a></li>
    <li><a href="#s5">Three Types of Missing Values</a></li>
    <li><a href="#s6">Handling Missing Values</a></li>
    <li><a href="#s7">Feature Scaling</a></li>
    <li><a href="#s8">High Cardinality Features &amp; Embeddings</a></li>
    <li><a href="#s9">Embedding Models: Word2Vec, GloVe, BERT</a></li>
    <li><a href="#s10">Data Leakage</a></li>
    <li><a href="#s11">Best Practices for Data Preprocessing</a></li>
    <li><a href="#s12">Feature Selection</a></li>
    <li><a href="#s13">Feature Selection Methods</a></li>
    <li><a href="#s14">Shapley Values for Feature Selection</a></li>
    <li><a href="#s15">Key Takeaways</a></li>
  </ol>
</nav>

<!-- SECTION 1 -->
<section id="s1">
  <h2>1. Deep Learning &amp; Automatic Feature Creation</h2>
  <p>Deep learning models automatically learn their own features as internal representations, removing much of the need for manual feature engineering in certain domains.</p>

  <div class="card teal">
    <strong>How It Works</strong>
    In a deep neural network, lower layers learn raw features (edges, corners for images). As data passes through successive layers of convolution, pooling, and transformation, the model creates progressively higher-order, abstract features internally.
  </div>

  <h3>1.1 Automatic Features by Data Type</h3>
  <table>
    <tr><th class="teal" style="width:20%">Data Type</th><th class="teal">Automatic Feature Learning</th><th class="teal">Details</th></tr>
    <tr>
      <td><strong>Image</strong></td>
      <td><span class="badge green">Strong</span></td>
      <td>Lower layers learn raw features (edges, corners); later layers create higher-order abstract features through internal transformations</td>
    </tr>
    <tr>
      <td><strong>Audio</strong></td>
      <td><span class="badge green">Strong</span></td>
      <td>Similar hierarchical feature learning as images</td>
    </tr>
    <tr>
      <td><strong>Text</strong></td>
      <td><span class="badge orange">Moderate</span></td>
      <td>To some extent &mdash; transformer models with embeddings capture contextual representations; tokenization + embedding replaces manual bigrams/trigrams</td>
    </tr>
    <tr>
      <td><strong>Tabular/Log</strong></td>
      <td><span class="badge red">Weak</span></td>
      <td>Still requires manual feature engineering due to structured fields, schemas, and aggregations</td>
    </tr>
  </table>
</section>

<!-- SECTION 2 -->
<section id="s2">
  <h2>2. Why Feature Engineering Is Still Needed</h2>
  <p>Despite advances in deep learning, manual feature engineering remains essential in many real-world scenarios.</p>

  <div class="grid">
    <div class="card red">
      <strong>Explainability Requirements</strong>
      Industries like insurance, finance, and banking must explain decisions (e.g., why a mortgage was rejected or a credit score assigned). Deep learning models lack sufficient explainability.
    </div>
    <div class="card orange">
      <strong>Cybersecurity &amp; SOC Analysts</strong>
      Security analysts need to understand <em>why</em> a user is flagged as suspicious. Black-box models are not acceptable for security operations.
    </div>
    <div class="card purple">
      <strong>Log &amp; Structured Data</strong>
      Log data (IoT, endpoint agents) has nested fields, schemas, and requires parsing, transformations, and aggregations. Automatic feature learning does not work well here.
    </div>
    <div class="card teal">
      <strong>Domain-Specific Data</strong>
      Finance, healthcare, and many other domains deal with data types where deep learning models are not suitable. Feature engineering is still the standard approach.
    </div>
  </div>

  <div class="highlight">Just because embedding models exist doesn't mean you can always avoid feature engineering. The choice depends on data type, domain requirements, and explainability needs.</div>
</section>

<!-- SECTION 3 -->
<section id="s3">
  <h2>3. Traditional Text Preprocessing</h2>
  <p>Before modern embeddings, text data required a series of preprocessing steps to create usable features.</p>

  <h3>3.1 Text Preprocessing Pipeline</h3>
  <div class="flowchart">
    <div class="flow-step">Original Text</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step green">Remove Contractions</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step teal">Remove Punctuation</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step purple">Lowercase</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step orange">Remove Stop Words</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step red">Lemmatization</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step">Bag of Words</div>
  </div>

  <h3>3.2 Worked Example</h3>
  <table>
    <tr><th class="purple" style="width:30%">Step</th><th class="purple">Result</th></tr>
    <tr><td>Original</td><td>"I have a dog, he is sleeping"</td></tr>
    <tr><td>Remove contractions</td><td>"I have a dog, he is sleeping"</td></tr>
    <tr><td>Remove punctuation</td><td>"I have a dog he is sleeping"</td></tr>
    <tr><td>Lowercase</td><td>"i have a dog he is sleeping"</td></tr>
    <tr><td>Remove stop words</td><td>"I", "have", "dog", "is", "sleeping" (removed "a")</td></tr>
    <tr><td>Lemmatization</td><td>"I", "have", "dog", "sleep"</td></tr>
  </table>

  <div class="card">
    <strong>Stop Words</strong>
    Words like "a", "the", "is" appear in almost every text and carry no informational value. Removing them reduces noise.
  </div>

  <div class="card green">
    <strong>Lemmatization</strong>
    Reduces words to their root form: "sleeping", "slept", "sleep" &rarr; "sleep". This ensures different inflections of the same word are treated as one feature.
  </div>

  <h3>3.3 Modern Approach vs. Traditional</h3>
  <table>
    <tr><th style="width:30%">Approach</th><th>Method</th><th>Context Awareness</th></tr>
    <tr><td><strong>Traditional</strong></td><td>Bag of Words, bigrams, trigrams</td><td>No contextual understanding</td></tr>
    <tr><td><strong>Modern</strong></td><td>Tokenization + embeddings</td><td>Captures semantic relationships</td></tr>
  </table>

  <div class="card teal">
    <strong>FastText (Meta)</strong>
    A library for very fast text classification based on traditional text features. When speed is the priority, FastText is as fast as it gets.
  </div>
</section>

<!-- SECTION 4 -->
<section id="s4">
  <h2>4. Missing Value Treatment</h2>
  <p><span class="term">Missing values</span> are a critical data quality issue that must be addressed before feature engineering.</p>

  <h3>4.1 Common Sources of Missing Values</h3>
  <div class="grid">
    <div class="card orange">
      <strong>Surveys</strong>
      Respondents may skip fields they don't want to answer or don't have information for.
    </div>
    <div class="card purple">
      <strong>IoT &amp; Endpoint Logs</strong>
      Logs are collected locally and pushed to the cloud when buffers are full. Sampling, outages, or transfer failures cause missing rows and values.
    </div>
    <div class="card red">
      <strong>Customer &amp; Healthcare Data</strong>
      Sensitive data fields are frequently left blank for privacy reasons.
    </div>
  </div>
</section>

<!-- SECTION 5 -->
<section id="s5">
  <h2>5. Three Types of Missing Values</h2>

  <div class="diagram">
    <svg width="560" height="180" viewBox="0 0 560 180">
      <!-- MCAR -->
      <rect x="10" y="20" width="160" height="90" rx="10" fill="#2563eb" opacity="0.1" stroke="#2563eb" stroke-width="2"/>
      <text x="90" y="50" text-anchor="middle" font-weight="700" fill="#2563eb" font-size="13">MCAR</text>
      <text x="90" y="70" text-anchor="middle" fill="#64748b" font-size="11">Missing Completely</text>
      <text x="90" y="85" text-anchor="middle" fill="#64748b" font-size="11">At Random</text>
      <text x="90" y="102" text-anchor="middle" fill="#1e293b" font-size="10">No dependency</text>

      <!-- MAR -->
      <rect x="200" y="20" width="160" height="90" rx="10" fill="#ea580c" opacity="0.1" stroke="#ea580c" stroke-width="2"/>
      <text x="280" y="50" text-anchor="middle" font-weight="700" fill="#ea580c" font-size="13">MAR</text>
      <text x="280" y="70" text-anchor="middle" fill="#64748b" font-size="11">Missing</text>
      <text x="280" y="85" text-anchor="middle" fill="#64748b" font-size="11">At Random</text>
      <text x="280" y="102" text-anchor="middle" fill="#1e293b" font-size="10">Depends on other vars</text>

      <!-- MNAR -->
      <rect x="390" y="20" width="160" height="90" rx="10" fill="#dc2626" opacity="0.1" stroke="#dc2626" stroke-width="2"/>
      <text x="470" y="50" text-anchor="middle" font-weight="700" fill="#dc2626" font-size="13">MNAR</text>
      <text x="470" y="70" text-anchor="middle" fill="#64748b" font-size="11">Missing Not</text>
      <text x="470" y="85" text-anchor="middle" fill="#64748b" font-size="11">At Random</text>
      <text x="470" y="102" text-anchor="middle" fill="#1e293b" font-size="10">Depends on own value</text>

      <!-- Summary -->
      <text x="280" y="140" text-anchor="middle" fill="#64748b" font-size="11">MCAR: random &bull; MAR: depends on observed variable &bull; MNAR: depends on the missing value itself</text>

      <defs>
        <marker id="arrowSvg" markerWidth="10" markerHeight="7" refX="10" refY="3.5" orient="auto">
          <polygon points="0 0, 10 3.5, 0 7" fill="#64748b"/>
        </marker>
      </defs>
    </svg>
  </div>

  <table>
    <tr><th class="orange" style="width:15%">Type</th><th class="orange" style="width:30%">Definition</th><th class="orange">Example</th></tr>
    <tr>
      <td><strong>MCAR</strong></td>
      <td>Missingness is not related to any variable &mdash; completely random</td>
      <td>Respondents skip a question about favourite colour because of a <em>printing error</em> on some forms. The error is unrelated to the respondent's characteristics.</td>
    </tr>
    <tr>
      <td><strong>MAR</strong></td>
      <td>Missingness depends on another <em>observed</em> variable, not on the missing value itself</td>
      <td>Younger participants are more likely to not report their income &mdash; missingness depends on age, not on the income value. Or: a particular gender may not disclose their age. The correlation can be partial.</td>
    </tr>
    <tr>
      <td><strong>MNAR</strong></td>
      <td>Missingness depends on the <em>value of the missing variable itself</em></td>
      <td>High-income people don't disclose their income <em>because</em> it is high. Or: people with severe depression are less likely to answer questions about mental health status.</td>
    </tr>
  </table>

  <div class="card green">
    <strong>Quick Rule</strong>
    Does not depend on anything &rarr; <span class="term">MCAR</span>. Depends on another observed variable &rarr; <span class="term">MAR</span>. Depends on the value of that variable itself &rarr; <span class="term">MNAR</span>.
  </div>
</section>

<!-- SECTION 6 -->
<section id="s6">
  <h2>6. Handling Missing Values</h2>

  <h3>6.1 Deletion Approaches</h3>
  <table>
    <tr><th style="width:25%">Method</th><th>Description</th><th style="width:25%">Recommendation</th></tr>
    <tr>
      <td><strong>Row Deletion</strong></td>
      <td>Delete rows with missing values (e.g., row 1, 3, 6)</td>
      <td><span class="badge orange">Use Sparingly</span> OK if only a few rows are missing</td>
    </tr>
    <tr>
      <td><strong>Column Deletion</strong></td>
      <td>Delete entire columns that have missing values</td>
      <td><span class="badge red">Avoid</span> Almost never a good approach</td>
    </tr>
  </table>

  <h3>6.2 Imputation Methods</h3>
  <table>
    <tr><th class="green" style="width:25%">Data Type</th><th class="green">Imputation Strategy</th></tr>
    <tr><td><strong>Numerical</strong></td><td>Replace with <span class="term">mean</span> or <span class="term">median</span></td></tr>
    <tr><td><strong>Ordinal</strong></td><td>Replace with <span class="term">mode</span></td></tr>
    <tr><td><strong>General</strong></td><td><span class="term">Interpolation</span> between values</td></tr>
  </table>

  <div class="card red">
    <strong>Imputation Risks</strong>
    <strong>Bias:</strong> If observed incomes are $50,000 and $10,000, the imputed mean would be $30,000 &mdash; but the actual missing incomes might be $5,000, introducing bias.<br>
    <strong>Data Leakage:</strong> Imputation creates dependency between data points. If you impute using the mean (computed from all data) then split into train/test, information from training data leaks into the test set, causing overfitting.
  </div>

  <div class="card green">
    <strong>Correct Approach (Q&amp;A)</strong>
    Always <strong>split the data first</strong>, then impute within each split separately. This prevents information leakage from training data into the test set.
  </div>

  <div class="flowchart">
    <div class="flow-step red">Raw Data</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step">Split into Train / Test</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step green">Impute Train Set</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step teal">Impute Test Set (separately)</div>
  </div>
</section>

<!-- SECTION 7 -->
<section id="s7">
  <h2>7. Feature Scaling</h2>
  <p>Features have different natural ranges (age: 0&ndash;100, income: thousands to hundreds of thousands, children: single digits). Models treat everything as raw numbers, so differing scales cause estimation errors.</p>

  <h3>7.1 Scaling Methods</h3>
  <table>
    <tr><th class="teal" style="width:25%">Method</th><th class="teal">How It Works</th><th class="teal" style="width:25%">Result Range</th></tr>
    <tr>
      <td><strong>Min-Max Scaling</strong></td>
      <td>X<sub>scaled</sub> = (X &minus; X<sub>min</sub>) / (X<sub>max</sub> &minus; X<sub>min</sub>)</td>
      <td>[0, 1]</td>
    </tr>
    <tr>
      <td><strong>Box-Cox Transform</strong></td>
      <td>Converts skewed feature distributions to approximate a <span class="term">Gaussian distribution</span>. Useful when models assume normal distribution (linear/logistic regression).</td>
      <td>~Normal</td>
    </tr>
    <tr>
      <td><strong>Binning</strong></td>
      <td>Convert continuous values into discrete buckets (e.g., age: 0&ndash;10, 10&ndash;20, 20&ndash;30, etc.). Reduces noise and smooths distribution.</td>
      <td>Discrete categories</td>
    </tr>
    <tr>
      <td><strong>One-Hot Encoding</strong></td>
      <td>Convert categorical features into binary indicator columns</td>
      <td>{0, 1} per category</td>
    </tr>
  </table>

  <h3>7.2 Worked Examples</h3>

  <p><strong>Min-Max Scaling:</strong> Suppose ages in your dataset are [5, 25, 45, 65]. Min = 5, Max = 65.</p>
  <table>
    <tr><th style="width:25%">Raw Age</th><th>Calculation</th><th style="width:25%">Scaled Value</th></tr>
    <tr><td>5</td><td>(5 &minus; 5) / (65 &minus; 5) = 0 / 60</td><td>0.00</td></tr>
    <tr><td>25</td><td>(25 &minus; 5) / (65 &minus; 5) = 20 / 60</td><td>0.33</td></tr>
    <tr><td>45</td><td>(45 &minus; 5) / (65 &minus; 5) = 40 / 60</td><td>0.67</td></tr>
    <tr><td>65</td><td>(65 &minus; 5) / (65 &minus; 5) = 60 / 60</td><td>1.00</td></tr>
  </table>

  <p><strong>One-Hot Encoding:</strong> Suppose you have a "Color" feature with values: Red, Blue, Green.</p>
  <table>
    <tr><th>Original</th><th>is_Red</th><th>is_Blue</th><th>is_Green</th></tr>
    <tr><td>Red</td><td>1</td><td>0</td><td>0</td></tr>
    <tr><td>Blue</td><td>0</td><td>1</td><td>0</td></tr>
    <tr><td>Green</td><td>0</td><td>0</td><td>1</td></tr>
    <tr><td>Red</td><td>1</td><td>0</td><td>0</td></tr>
  </table>

  <p><strong>Binning:</strong> Instead of raw ages [3, 7, 15, 22, 31, 48, 55, 72], create buckets:</p>
  <table>
    <tr><th>Raw Age</th><th>Bin (Bucket)</th></tr>
    <tr><td>3, 7</td><td>0&ndash;10</td></tr>
    <tr><td>15</td><td>10&ndash;20</td></tr>
    <tr><td>22</td><td>20&ndash;30</td></tr>
    <tr><td>31</td><td>30&ndash;40</td></tr>
    <tr><td>48, 55</td><td>40&ndash;60</td></tr>
    <tr><td>72</td><td>60&ndash;80</td></tr>
  </table>

  <div class="card orange">
    <strong>When to Use Binning</strong>
    Quantities like age often have uneven distributions (few children, many middle-aged, few elderly). Converting raw age into ranges (buckets) reduces noise and produces smoother distributions. The number of buckets depends on the problem.
  </div>

  <div class="highlight">Box-Cox transformation creates dependency between data points. Like imputation, it should be applied <strong>after</strong> splitting into train/test sets, not before.</div>
</section>

<!-- SECTION 8 -->
<section id="s8">
  <h2>8. High Cardinality Features &amp; Embeddings</h2>
  <p><span class="term">High cardinality features</span> like zip codes and IP addresses have a massive number of unique values. Keeping them as-is is not useful for models. The solution is <span class="term">embeddings</span>.</p>

  <div class="card purple">
    <strong>What Is an Embedding?</strong>
    A fixed-size numerical vector representing a word, sentence, or entity. The key property: <strong>similar items are close together</strong> in the embedding space.
  </div>

  <h3>8.1 How Embeddings Work</h3>

  <div class="diagram">
    <svg width="480" height="200" viewBox="0 0 480 200">
      <!-- Embedding space -->
      <rect x="10" y="10" width="460" height="180" rx="12" fill="#f0f9ff" stroke="#2563eb" stroke-width="1.5"/>
      <text x="240" y="32" text-anchor="middle" font-weight="700" fill="#2563eb" font-size="13">Embedding Space</text>

      <!-- Close words -->
      <circle cx="100" cy="90" r="6" fill="#16a34a"/>
      <text x="115" y="95" fill="#1e293b" font-size="12" font-weight="600">"cat"</text>
      <circle cx="130" cy="110" r="6" fill="#16a34a"/>
      <text x="145" y="115" fill="#1e293b" font-size="12" font-weight="600">"kitten"</text>

      <!-- Distance line between close words -->
      <line x1="106" y1="93" x2="125" y2="107" stroke="#16a34a" stroke-width="1.5" stroke-dasharray="4,3"/>

      <!-- Far word -->
      <circle cx="370" cy="130" r="6" fill="#dc2626"/>
      <text x="385" y="135" fill="#1e293b" font-size="12" font-weight="600">"house"</text>

      <!-- Analogy example -->
      <circle cx="220" cy="80" r="6" fill="#7c3aed"/>
      <text x="235" y="85" fill="#1e293b" font-size="12" font-weight="600">"man"</text>
      <circle cx="320" cy="80" r="6" fill="#7c3aed"/>
      <text x="335" y="85" fill="#1e293b" font-size="12" font-weight="600">"king"</text>
      <circle cx="220" cy="140" r="6" fill="#ea580c"/>
      <text x="235" y="145" fill="#1e293b" font-size="12" font-weight="600">"woman"</text>
      <circle cx="320" cy="140" r="6" fill="#ea580c"/>
      <text x="335" y="145" fill="#1e293b" font-size="12" font-weight="600">"queen"</text>

      <!-- Arrows for analogy -->
      <line x1="226" y1="80" x2="312" y2="80" stroke="#7c3aed" stroke-width="1.5" marker-end="url(#arrEmb)"/>
      <line x1="226" y1="140" x2="312" y2="140" stroke="#ea580c" stroke-width="1.5" marker-end="url(#arrEmb)"/>

      <text x="270" y="172" text-anchor="middle" fill="#64748b" font-size="11">king &minus; man &asymp; queen &minus; woman</text>

      <defs>
        <marker id="arrEmb" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto">
          <polygon points="0 0, 8 3, 0 6" fill="#64748b"/>
        </marker>
      </defs>
    </svg>
  </div>

  <h3>8.2 Sentence Embeddings</h3>
  <p>To represent an entire sentence as a single vector:</p>
  <div class="grid">
    <div class="card green">
      <strong>Average Pooling</strong>
      Average all word vectors in the sentence to create one vector. Most commonly used.
    </div>
    <div class="card">
      <strong>Max Pooling</strong>
      Take the max value across each dimension of the word vectors.
    </div>
    <div class="card orange">
      <strong>Concatenation</strong>
      Concatenate all word vectors. Creates a very large vector &mdash; less practical.
    </div>
  </div>

  <h3>8.2.1 Worked Example: Sentence Pooling</h3>
  <p>Sentence: <strong>"I have dog"</strong> &mdash; suppose each word has a 4-dimensional embedding:</p>
  <table>
    <tr><th class="purple">Word</th><th class="purple">Dim 1</th><th class="purple">Dim 2</th><th class="purple">Dim 3</th><th class="purple">Dim 4</th></tr>
    <tr><td>"I"</td><td>0.2</td><td>0.8</td><td>0.1</td><td>0.5</td></tr>
    <tr><td>"have"</td><td>0.6</td><td>0.3</td><td>0.9</td><td>0.2</td></tr>
    <tr><td>"dog"</td><td>0.4</td><td>0.7</td><td>0.3</td><td>0.8</td></tr>
  </table>
  <table>
    <tr><th class="green" style="width:25%">Method</th><th class="green">Calculation</th><th class="green">Result Vector</th></tr>
    <tr>
      <td><strong>Average Pooling</strong></td>
      <td>Average each dimension:<br>(0.2+0.6+0.4)/3, (0.8+0.3+0.7)/3, (0.1+0.9+0.3)/3, (0.5+0.2+0.8)/3</td>
      <td><strong>[0.4, 0.6, 0.43, 0.5]</strong> &mdash; 4 dims</td>
    </tr>
    <tr>
      <td><strong>Max Pooling</strong></td>
      <td>Max of each dimension:<br>max(0.2,0.6,0.4), max(0.8,0.3,0.7), max(0.1,0.9,0.3), max(0.5,0.2,0.8)</td>
      <td><strong>[0.6, 0.8, 0.9, 0.8]</strong> &mdash; 4 dims</td>
    </tr>
    <tr>
      <td><strong>Concatenation</strong></td>
      <td>Stick all vectors end-to-end:<br>[0.2,0.8,0.1,0.5] + [0.6,0.3,0.9,0.2] + [0.4,0.7,0.3,0.8]</td>
      <td><strong>[0.2, 0.8, 0.1, 0.5, 0.6, 0.3, 0.9, 0.2, 0.4, 0.7, 0.3, 0.8]</strong> &mdash; 12 dims</td>
    </tr>
  </table>
  <div class="highlight">Average and max pooling keep the same size as a single word embedding (4 dims). Concatenation multiplies the size by the number of words (3 &times; 4 = 12 dims), which becomes impractical for long sentences.</div>

  <h3>8.3 Why Embeddings Are Powerful</h3>
  <p>They preserve <span class="term">semantic relationships</span>. If "dog" is in training data and "kitten" appears at inference, the model understands it is talking about something similar to "cat." "House" would be treated as very different. The embedding size is configurable &mdash; e.g., a vector of size 7, or typically a few hundred dimensions.</p>
</section>

<!-- SECTION 9 -->
<section id="s9">
  <h2>9. Embedding Models: Word2Vec, GloVe, BERT</h2>

  <table>
    <tr><th class="purple" style="width:18%">Model</th><th class="purple" style="width:18%">Origin</th><th class="purple">Method</th></tr>
    <tr>
      <td><strong>Word2Vec</strong></td>
      <td>~10 years ago</td>
      <td>Small neural network with two variants:<br>
        &bull; <span class="term">CBOW</span> (Continuous Bag of Words): predict the current word from surrounding words<br>
        &bull; <span class="term">Skip-gram</span>: predict surrounding words from the current word<br>
        The hidden layer of the trained network becomes the embedding.<br><br>
        <em>Example sentence:</em> "the cat <strong>sat</strong> on the"<br>
        &bull; CBOW: given ["the", "cat", "on", "the"] &rarr; predict "<strong>sat</strong>"<br>
        &bull; Skip-gram: given "<strong>sat</strong>" &rarr; predict ["the", "cat", "on", "the"]
      </td>
    </tr>
    <tr>
      <td><strong>GloVe</strong></td>
      <td>Stanford</td>
      <td>Global Vectors for Word Representation. Improved embedding model from Stanford University.</td>
    </tr>
    <tr>
      <td><strong>BERT</strong></td>
      <td>Google</td>
      <td><span class="term">Bidirectional Encoder Representations from Transformers</span>. Train on large corpus, then take the second-to-last layer (not the final logistic layer) as the embedding. The final layer converts to class probabilities; the layer before it is a rich numerical representation.<br><br>
        <em>Example:</em> A 3-layer BERT classifying sentiment:<br>
        Layer 1: [0.3, 0.7, 0.1, ...] (raw features)<br>
        Layer 2: [0.8, 0.2, 0.5, ...] &larr; <strong>use this as embedding</strong><br>
        Layer 3 (final): [0.9 positive, 0.1 negative] (class probabilities &mdash; don't use this)
      </td>
    </tr>
  </table>

  <h3>9.1 Modern Embedding Ecosystem</h3>
  <div class="card teal">
    <strong>Hugging Face</strong>
    Hosts a dedicated tab for embedding models with a leaderboard. Leading models include Snowflake and Alibaba embeddings. Open-source embedding models can be downloaded just like LLMs (e.g., LLaMA).
  </div>

  <div class="card">
    <strong>MTEB Benchmark</strong>
    The <span class="term">Massive Text Embedding Benchmark</span> ranks embedding models. Embedding dimensions range widely &mdash; e.g., 4096 dimensions (very large) vs. &lt;1000 (more practical). Higher dimensions increase computational cost and memory usage without always improving results.
  </div>

  <div class="highlight">Choose your embedding dimension based on your problem complexity. Higher dimensions are not always better &mdash; they increase compute and memory costs.</div>
</section>

<!-- SECTION 10 -->
<section id="s10">
  <h2>10. Data Leakage</h2>
  <p><span class="term">Data leakage</span> occurs when information from the training set inadvertently appears in the validation or test set, leading to overly optimistic performance metrics during development that don't hold in production.</p>

  <div class="card red">
    <strong>Warning Sign</strong>
    If your model performs unexpectedly well during development but poorly in production, data leakage is a likely cause.
  </div>

  <h3>10.1 Causes of Data Leakage</h3>
  <table>
    <tr><th class="red" style="width:25%">Cause</th><th class="red">Description</th><th class="red">Example</th></tr>
    <tr>
      <td><strong>Aggregate Features</strong></td>
      <td>A feature derived from another feature creates dependency</td>
      <td>Using both monthly salary and yearly salary (= 12 &times; monthly) as features leaks information between them</td>
    </tr>
    <tr>
      <td><strong>Duplicate Data</strong></td>
      <td>Duplicate records split across train and test sets</td>
      <td>One copy of a duplicate ends up in training, the other in test &mdash; the model has already "seen" the test data</td>
    </tr>
    <tr>
      <td><strong>Temporal Dependency</strong></td>
      <td>Time series data randomly split violates the i.i.d. assumption</td>
      <td>Autocorrelated observations from adjacent time periods end up in both train and test, leaking future information</td>
    </tr>
  </table>

  <div class="card orange">
    <strong>Time Series Rule</strong>
    Never use random splitting for time series data. Always split by time: training data up to time T<sub>1</sub>, validation from T<sub>1</sub> to T<sub>2</sub>, test from T<sub>2</sub> onward. Time series data violates the <span class="term">i.i.d.</span> (identically and independently distributed) assumption due to autocorrelation.
  </div>
</section>

<!-- SECTION 11 -->
<section id="s11">
  <h2>11. Best Practices for Data Preprocessing</h2>

  <h3>11.1 Correct Order of Operations</h3>
  <div class="flowchart">
    <div class="flow-step red">Remove Duplicates</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step">Split Data (Train / Val / Test)</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step green">Impute Missing Values</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step teal">Scale / Transform Features</div>
    <span class="flow-arrow">&rarr;</span>
    <div class="flow-step purple">Oversample (if needed)</div>
  </div>

  <h3>11.2 Rules Summary</h3>
  <div class="grid">
    <div class="card green">
      <strong>Split Before Imputation</strong>
      Never impute before splitting. Impute within each split separately to avoid leakage.
    </div>
    <div class="card">
      <strong>Split Before Scaling</strong>
      Box-Cox and other transformations create dependencies. Apply after splitting, using statistics from the training data only.
    </div>
    <div class="card orange">
      <strong>Remove Duplicates First</strong>
      Duplicate removal must happen before splitting to prevent the same record appearing in both train and test.
    </div>
    <div class="card red">
      <strong>Check Feature-Target Correlation</strong>
      If a feature is highly correlated with the target, it may be a sign of data leakage. Investigate before proceeding.
    </div>
  </div>

  <h3>11.3 Splitting Strategies</h3>
  <table>
    <tr><th style="width:30%">Data Type</th><th>Splitting Method</th></tr>
    <tr><td><strong>Non-time-series</strong></td><td>Random splitting or stratified splitting</td></tr>
    <tr><td><strong>Time series</strong></td><td>Split by time (chronological order)</td></tr>
  </table>

  <h3>11.4 Autocorrelation</h3>
  <p>For time series data, <span class="term">temporal correlation</span> is measured using the <span class="term">autocorrelation function (ACF)</span>: compute the correlation between X(t) and X(t + &tau;). This identifies the time scale within which observations are dependent.</p>

  <p><strong>Example:</strong> Daily temperature readings: [20, 21, 22, 23, 22, 21]. Today's temperature (t) is very similar to yesterday's (t&minus;1) and the day before (t&minus;2). The ACF would show high correlation at lag 1 and lag 2, meaning observations within a 2-day window are dependent. Randomly splitting this data would leak information &mdash; the model could "see" tomorrow's temperature in training and a nearby day in the test set.</p>

  <div class="card teal">
    <strong>Data Lineage &amp; Versioning</strong>
    Keep track of data lineage (how data was processed at each step). Data versioning is as important as model versioning &mdash; it lets you trace back and diagnose why a model failed.
  </div>
</section>

<!-- SECTION 12 -->
<section id="s12">
  <h2>12. Feature Selection</h2>
  <p>After engineering many features, you need to select an optimal subset. More features are not always better.</p>

  <h3>12.1 Why Reduce Features?</h3>
  <div class="grid">
    <div class="card red">
      <strong>Overfitting</strong>
      If the number of features exceeds the number of data points, the model overfits. From linear algebra: when columns &gt; rows, you don't get a good solution.
    </div>
    <div class="card orange">
      <strong>Computational Cost</strong>
      More features require more memory and computation during both training and inference.
    </div>
    <div class="card purple">
      <strong>Inference Latency</strong>
      At prediction time, all features must be fetched and processed. More features = higher latency.
    </div>
    <div class="card teal">
      <strong>Data Requirements</strong>
      More features require more training data to properly estimate model parameters.
    </div>
  </div>

  <h3>12.2 Two Selection Criteria</h3>
  <table>
    <tr><th class="green" style="width:30%">Criterion</th><th class="green">Description</th></tr>
    <tr>
      <td><strong>1. Feature Importance</strong></td>
      <td>Does adding this feature increase the model's accuracy or performance metric? Compare model performance with vs. without the feature.</td>
    </tr>
    <tr>
      <td><strong>2. Generalization</strong></td>
      <td>Does this feature help the model perform well on <em>unseen data</em> in production? A feature may help on training/validation but hurt on new data with different distributions.</td>
    </tr>
  </table>
</section>

<!-- SECTION 13 -->
<section id="s13">
  <h2>13. Feature Selection Methods</h2>

  <h3>13.1 Forward &amp; Backward Selection</h3>
  <table>
    <tr><th class="purple" style="width:25%">Method</th><th class="purple">Process</th></tr>
    <tr>
      <td><strong>Forward Selection</strong></td>
      <td>Start with one feature. Add one feature at a time, keeping whichever addition improves accuracy most. Repeat recursively until no improvement.</td>
    </tr>
    <tr>
      <td><strong>Backward Elimination</strong></td>
      <td>Start with all features. Remove one feature at a time, dropping whichever removal hurts accuracy least. Repeat until further removal degrades performance.</td>
    </tr>
  </table>

  <p><strong>Forward Selection Example:</strong> Suppose you have features A, B, C, D.</p>
  <table>
    <tr><th class="green" style="width:15%">Round</th><th class="green">Try</th><th class="green">Best Accuracy</th><th class="green">Keep</th></tr>
    <tr><td>1</td><td>A alone, B alone, C alone, D alone</td><td>B = 72%</td><td>{B}</td></tr>
    <tr><td>2</td><td>B+A, B+C, B+D</td><td>B+D = 81%</td><td>{B, D}</td></tr>
    <tr><td>3</td><td>B+D+A, B+D+C</td><td>B+D+A = 82%, B+D+C = 80%</td><td>{B, D, A} (small gain &mdash; may stop here)</td></tr>
  </table>

  <h3>13.2 Interaction Features</h3>
  <div class="card orange">
    <strong>Combinatorial Complexity</strong>
    N features produce a factorial number of possible combinations. Use domain knowledge to identify which interactions are worth testing. First-order interactions tend to be more important than higher-order ones. Beyond second-order, interactions rarely contribute significantly.
  </div>

  <h3>13.3 Entropy-Based Methods</h3>
  <div class="card">
    <strong>Entropy-Based Criterion</strong>
    Compute the entropy difference between the model with a feature included vs. excluded. Rank features by this entropy-based criterion and select the top ones.
  </div>

  <h3>13.4 PCA Limitations</h3>
  <div class="card red">
    <strong>PCA for Feature Selection</strong>
    PCA assumes linear relationships and may not capture nonlinear dependencies. While it can be used for dimensionality reduction, it has significant limitations when features have nonlinear interactions.
  </div>
</section>

<!-- SECTION 14 -->
<section id="s14">
  <h2>14. Shapley Values for Feature Selection</h2>
  <p><span class="badge purple">Game Theory</span> <span class="term">Shapley values</span>, invented by Lloyd Shapley, are a concept borrowed from cooperative game theory. They calculate the contribution of each feature (player) to the model's prediction (game outcome).</p>

  <div class="card purple">
    <strong>Core Idea</strong>
    Think of the model as a cooperative game where all features work together to produce a prediction. Shapley values calculate how much each feature contributes to that prediction. Based on these contributions, you decide which features to keep.
  </div>

  <h3>14.1 Two Levels of Shapley Analysis</h3>

  <div class="diagram">
    <svg width="520" height="180" viewBox="0 0 520 180">
      <!-- Global -->
      <rect x="10" y="20" width="240" height="130" rx="10" fill="#7c3aed" opacity="0.1" stroke="#7c3aed" stroke-width="2"/>
      <text x="130" y="50" text-anchor="middle" font-weight="700" fill="#7c3aed" font-size="14">Global Level</text>
      <text x="130" y="72" text-anchor="middle" fill="#1e293b" font-size="11">Model-wide analysis</text>
      <text x="130" y="90" text-anchor="middle" fill="#64748b" font-size="11">Which features matter</text>
      <text x="130" y="106" text-anchor="middle" fill="#64748b" font-size="11">overall for the model?</text>
      <text x="130" y="128" text-anchor="middle" fill="#7c3aed" font-size="11" font-weight="600">Use: Feature Selection</text>

      <!-- Local -->
      <rect x="270" y="20" width="240" height="130" rx="10" fill="#0d9488" opacity="0.1" stroke="#0d9488" stroke-width="2"/>
      <text x="390" y="50" text-anchor="middle" font-weight="700" fill="#0d9488" font-size="14">Local Level</text>
      <text x="390" y="72" text-anchor="middle" fill="#1e293b" font-size="11">Individual prediction</text>
      <text x="390" y="90" text-anchor="middle" fill="#64748b" font-size="11">Which features drove</text>
      <text x="390" y="106" text-anchor="middle" fill="#64748b" font-size="11">this specific outcome?</text>
      <text x="390" y="128" text-anchor="middle" fill="#0d9488" font-size="11" font-weight="600">Use: Explainability</text>
    </svg>
  </div>

  <table>
    <tr><th class="purple" style="width:20%">Level</th><th class="purple">Purpose</th><th class="purple">Example</th></tr>
    <tr>
      <td><strong>Global</strong></td>
      <td>Identify which features are most important across the entire model. Used during development for feature selection.</td>
      <td>Sort all features by Shapley value. Keep top features; discard those below a cutoff.</td>
    </tr>
    <tr>
      <td><strong>Local</strong></td>
      <td>Explain why a specific prediction was made. Used in production for individual decision explainability.</td>
      <td>A loan rejection: one feature has Shapley value +4.98 (pushing toward rejection), another has &minus;2 (pushing against rejection). These two features contributed most to the rejection decision.</td>
    </tr>
  </table>

  <h3>14.2 Interpreting Shapley Plots</h3>
  <div class="card teal">
    <strong>Reading the Visualization</strong>
    In a Shapley value plot for a classification problem:<br>
    &bull; Each feature shows its importance value<br>
    &bull; Color indicates whether importance is low or high<br>
    &bull; Direction shows whether the feature contributes toward the positive or negative class<br>
    &bull; Features are sorted by overall contribution, making it easy to identify and cut off low-value features
  </div>

  <h3>14.3 Credit Scoring Example</h3>
  <p>In a real credit scoring model, the top Shapley features include:</p>
  <div class="score-bar-container">
    <div class="score-label">1. Payment Gap (first payment date &minus; first due date)</div>
    <div class="score-bar"><div class="score-fill" style="width:95%; background: var(--accent-red);">Highest impact</div></div>
  </div>
  <div class="score-bar-container">
    <div class="score-label">2. GPS Location (latitude/longitude)</div>
    <div class="score-bar"><div class="score-fill" style="width:70%; background: var(--accent-orange);">High impact</div></div>
  </div>
  <div class="score-bar-container">
    <div class="score-label">3. Account Creation Date</div>
    <div class="score-bar"><div class="score-fill" style="width:55%; background: var(--accent-purple);">Moderate impact</div></div>
  </div>
  <div class="score-bar-container">
    <div class="score-label">4. Due Day of the Week</div>
    <div class="score-bar"><div class="score-fill" style="width:40%; background: var(--accent-teal);">Moderate impact</div></div>
  </div>
  <div class="score-bar-container">
    <div class="score-label">5. Age</div>
    <div class="score-bar"><div class="score-fill" style="width:30%; background: var(--accent-blue);">Lower impact</div></div>
  </div>

  <div class="card green">
    <strong>Practical Takeaway</strong>
    The most important credit scoring feature is the gap between when your credit card payment was due and when you actually paid. Pay your bills on time!
  </div>
</section>

<!-- SECTION 15 -->
<section id="s15">
  <h2>15. Key Takeaways</h2>

  <div class="grid">
    <div class="card teal">
      <strong>1. Deep Learning Automates Feature Creation &mdash; Sometimes</strong>
      CNNs and transformers learn features automatically for image, audio, and text. But tabular, log, and structured data still require manual feature engineering.
    </div>
    <div class="card red">
      <strong>2. Explainability Demands Feature Engineering</strong>
      Finance, insurance, healthcare, and cybersecurity industries often require explainable models, ruling out deep learning black boxes.
    </div>
    <div class="card purple">
      <strong>3. Handle Missing Values Carefully</strong>
      Understand the type (MCAR, MAR, MNAR). Prefer imputation over deletion. Always split data before imputing to prevent leakage.
    </div>
    <div class="card orange">
      <strong>4. Scale and Transform After Splitting</strong>
      Min-Max scaling, Box-Cox transformations, and oversampling must all happen after the train/test split to maintain data independence.
    </div>
    <div class="card">
      <strong>5. Embeddings Are the Modern Standard</strong>
      Word2Vec, GloVe, and BERT-based embeddings preserve semantic relationships. Choose embedding dimensions based on task complexity and compute budget.
    </div>
    <div class="card green">
      <strong>6. Guard Against Data Leakage</strong>
      Watch for aggregate features, duplicates, temporal dependencies, and pre-split transformations. If a model performs too well in development, suspect leakage.
    </div>
    <div class="card red">
      <strong>7. Select Features Strategically</strong>
      Use forward/backward selection, entropy methods, or Shapley values. Shapley values provide both global feature selection and local prediction explainability.
    </div>
    <div class="card teal">
      <strong>8. Data Lineage Matters</strong>
      Track how data is processed at each step. Data versioning is as important as model versioning for debugging model failures.
    </div>
  </div>
</section>

</div>
</body>
</html>